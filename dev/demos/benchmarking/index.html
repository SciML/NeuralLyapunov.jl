<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Benchmarking a neural Lyapunov method · NeuralLyapunov.jl</title><meta name="title" content="Benchmarking a neural Lyapunov method · NeuralLyapunov.jl"/><meta property="og:title" content="Benchmarking a neural Lyapunov method · NeuralLyapunov.jl"/><meta property="twitter:title" content="Benchmarking a neural Lyapunov method · NeuralLyapunov.jl"/><meta name="description" content="Documentation for NeuralLyapunov.jl."/><meta property="og:description" content="Documentation for NeuralLyapunov.jl."/><meta property="twitter:description" content="Documentation for NeuralLyapunov.jl."/><meta property="og:url" content="https://SciML.github.io/NeuralLyapunov.jl/demos/benchmarking/"/><meta property="twitter:url" content="https://SciML.github.io/NeuralLyapunov.jl/demos/benchmarking/"/><link rel="canonical" href="https://SciML.github.io/NeuralLyapunov.jl/demos/benchmarking/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralLyapunov.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../../man/">Components of a Neural Lyapunov Problem</a></li><li><a class="tocitem" href="../../man/pdesystem/">Solving a Neural Lyapunov Problem</a></li><li><a class="tocitem" href="../../man/minimization/">Lyapunov Minimization Condition</a></li><li><a class="tocitem" href="../../man/decrease/">Lyapunov Decrease Condition</a></li><li><a class="tocitem" href="../../man/structure/">Structuring a Neural Lyapunov function</a></li><li><a class="tocitem" href="../../man/roa/">Training for Region of Attraction Identification</a></li><li><a class="tocitem" href="../../man/policy_search/">Policy Search and Network-Dependent Dynamics</a></li><li><a class="tocitem" href="../../man/local_lyapunov/">Local Lyapunov analysis</a></li></ul></li><li><span class="tocitem">Demonstrations</span><ul><li><a class="tocitem" href="../damped_SHO/">Damped Simple Harmonic Oscillator</a></li><li><a class="tocitem" href="../roa_estimation/">Estimating the Region of Attraction</a></li><li><a class="tocitem" href="../policy_search/">Policy Search on the Driven Inverted Pendulum</a></li><li class="is-active"><a class="tocitem" href>Benchmarking a neural Lyapunov method</a><ul class="internal"><li><a class="tocitem" href="#Copy-Pastable-Code"><span>Copy-Pastable Code</span></a></li><li><a class="tocitem" href="#Detailed-Description"><span>Detailed Description</span></a></li></ul></li></ul></li><li><span class="tocitem">Test Problem Library</span><ul><li><a class="tocitem" href="../../lib/">NeuralLyapunovProblemLibrary.jl</a></li><li><a class="tocitem" href="../../lib/pendulum/">Pendulum Model</a></li><li><a class="tocitem" href="../../lib/double_pendulum/">Double Pendulum Model</a></li><li><a class="tocitem" href="../../lib/quadrotor/">Quadrotor Models</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Demonstrations</a></li><li class="is-active"><a href>Benchmarking a neural Lyapunov method</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Benchmarking a neural Lyapunov method</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/NeuralLyapunov.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/NeuralLyapunov.jl/blob/master/docs/src/demos/benchmarking.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Benchmarking-a-neural-Lyapunov-method"><a class="docs-heading-anchor" href="#Benchmarking-a-neural-Lyapunov-method">Benchmarking a neural Lyapunov method</a><a id="Benchmarking-a-neural-Lyapunov-method-1"></a><a class="docs-heading-anchor-permalink" href="#Benchmarking-a-neural-Lyapunov-method" title="Permalink"></a></h1><p>In this demonstration, we&#39;ll benchmark the neural Lyapunov method used in the <a href="../policy_search/">policy search demo</a>. In that demonstration, we searched for a neural network policy to stabilize the upright equilibrium of the inverted pendulum. Here, we will use the <a href="../../man/benchmarking/#NeuralLyapunov.benchmark"><code>benchmark</code></a> function to run approximately the same training, then check the performance the of the resulting controller and neural Lyapunov function by simulating the closed loop system to see (1) how well the controller drives the pendulum to the upright equilibrium, and (2) how well the neural Lyapunov function performs as a classifier of whether a state is in the region of attraction or not. These results will be represented by a confusion matrix using the simulation results as ground truth. (Keep in mind that training does no simulation.)</p><h2 id="Copy-Pastable-Code"><a class="docs-heading-anchor" href="#Copy-Pastable-Code">Copy-Pastable Code</a><a id="Copy-Pastable-Code-1"></a><a class="docs-heading-anchor-permalink" href="#Copy-Pastable-Code" title="Permalink"></a></h2><pre><code class="language-julia hljs">using NeuralPDE, NeuralLyapunov, Lux
using Boltz.Layers: PeriodicEmbedding
import OptimizationOptimisers, OptimizationOptimJL
using StableRNGs, Random

rng = StableRNG(0)
Random.seed!(200)

# Define dynamics and domain
function open_loop_pendulum_dynamics(x, u, p, t)
    θ, ω = x
    ζ, ω_0 = p
    τ = u[]
    return [ω, -2ζ * ω_0 * ω - ω_0^2 * sin(θ) + τ]
end

lb = Float32[0.0, -2.0];
ub = Float32[2π, 2.0];
upright_equilibrium = Float32[π, 0.0]
p = Float32[0.5, 1.0]
state_syms = [:θ, :ω]
parameter_syms = [:ζ, :ω_0]

# Define neural network discretization
# We use an input layer that is periodic with period 2π with respect to θ
dim_state = length(lb)
dim_hidden = 25
dim_phi = 3
dim_u = 1
dim_output = dim_phi + dim_u
chain = [Chain(
             PeriodicEmbedding([1], Float32[2π]),
             Dense(dim_state + 1, dim_hidden, tanh),
             Dense(dim_hidden, dim_hidden, tanh),
             Dense(dim_hidden, 1)
         ) for _ in 1:dim_output]
ps, st = Lux.setup(rng, chain)

# Define neural network discretization
strategy = QuasiRandomTraining(10000)

# Define neural Lyapunov structure
periodic_pos_def = function (state, fixed_point)
    θ, ω = state
    θ_eq, ω_eq = fixed_point
    return (sin(θ) - sin(θ_eq))^2 + (cos(θ) - cos(θ_eq))^2 + (ω - ω_eq)^2 / 10
end

structure = PositiveSemiDefiniteStructure(
    dim_phi;
    pos_def = (x, x0) -&gt; log(1 + periodic_pos_def(x, x0))
)
structure = add_policy_search(structure, dim_u)

minimization_condition = DontCheckNonnegativity(check_fixed_point = false)

# Define Lyapunov decrease condition
decrease_condition = AsymptoticStability(strength = periodic_pos_def)

# Construct neural Lyapunov specification
spec = NeuralLyapunovSpecification(structure, minimization_condition, decrease_condition)

# Define optimization parameters
opt = [OptimizationOptimisers.Adam(0.05f0), OptimizationOptimJL.BFGS()]
optimization_args = [[:maxiters =&gt; 300], [:maxiters =&gt; 300]]

# Run benchmark
endpoint_check = (x) -&gt; ≈([sin(x[1]), cos(x[1]), x[2]], [0, -1, 0], atol = 5e-3)
benchmarking_results = benchmark(
    open_loop_pendulum_dynamics,
    lb,
    ub,
    spec,
    chain,
    strategy,
    opt;
    simulation_time = 200,
    n = 1000,
    fixed_point = upright_equilibrium,
    p,
    optimization_args,
    state_syms,
    parameter_syms,
    policy_search = true,
    endpoint_check,
    init_params = ps, 
    init_states = st
)</code></pre><h2 id="Detailed-Description"><a class="docs-heading-anchor" href="#Detailed-Description">Detailed Description</a><a id="Detailed-Description-1"></a><a class="docs-heading-anchor-permalink" href="#Detailed-Description" title="Permalink"></a></h2><p>Much of the set up is the same as in the <a href="../policy_search/">policy search demo</a>, so see that page for details.</p><pre><code class="language-julia hljs">using NeuralPDE, NeuralLyapunov, Lux
import Boltz.Layers: PeriodicEmbedding
using Random, StableRNGs

Random.seed!(200)

# Define dynamics and domain
function open_loop_pendulum_dynamics(x, u, p, t)
    θ, ω = x
    ζ, ω_0 = p
    τ = u[]
    return [ω, -2ζ * ω_0 * ω - ω_0^2 * sin(θ) + τ]
end

lb = Float32[0.0, -2.0];
ub = Float32[2π, 2.0];
upright_equilibrium = Float32[π, 0.0]
p = Float32[0.5, 1.0]
state_syms = [:θ, :ω]
parameter_syms = [:ζ, :ω_0]

# Define neural network discretization
# We use an input layer that is periodic with period 2π with respect to θ
dim_state = length(lb)
dim_hidden = 25
dim_phi = 3
dim_u = 1
dim_output = dim_phi + dim_u
chain = [Chain(
             PeriodicEmbedding([1], Float32[2π]),
             Dense(3, dim_hidden, tanh),
             Dense(dim_hidden, dim_hidden, tanh),
             Dense(dim_hidden, 1)
         ) for _ in 1:dim_output]
ps, st = Lux.setup(StableRNG(0), chain)

# Define neural network discretization
strategy = QuasiRandomTraining(10000)

# Define neural Lyapunov structure
periodic_pos_def = function (state, fixed_point)
    θ, ω = state
    θ_eq, ω_eq = fixed_point
    return (sin(θ) - sin(θ_eq))^2 + (cos(θ) - cos(θ_eq))^2 + (ω - ω_eq)^2 / 10
end

structure = PositiveSemiDefiniteStructure(
    dim_phi;
    pos_def = (x, x0) -&gt; log(1 + periodic_pos_def(x, x0))
)
structure = add_policy_search(structure, dim_u)

minimization_condition = DontCheckNonnegativity(check_fixed_point = false)

# Define Lyapunov decrease condition
decrease_condition = AsymptoticStability(strength = periodic_pos_def)

# Construct neural Lyapunov specification
spec = NeuralLyapunovSpecification(structure, minimization_condition, decrease_condition)</code></pre><p>At this point of the <a href="../policy_search/">policy search demo</a>, we constructed the PDESystem, discretized it using NeuralPDE.jl, and solved the resulting OptimizationProblem using Optimization.jl. All of that occurs in the <a href="../../man/benchmarking/#NeuralLyapunov.benchmark"><code>benchmark</code></a> function, so we instead provide that function with the optimizer and optimization arguments to use.</p><pre><code class="language-julia hljs">import OptimizationOptimisers, OptimizationOptimJL

# Define optimization parameters
opt = [OptimizationOptimisers.Adam(0.05f0), OptimizationOptimJL.BFGS()]
optimization_args = [[:maxiters =&gt; 300], [:maxiters =&gt; 300]]</code></pre><p>Since the pendulum is periodic in <span>$0$</span>, we&#39;ll use a custom endpoint check that reflects that property.</p><pre><code class="language-julia hljs">endpoint_check = (x) -&gt; ≈([sin(x[1]), cos(x[1]), x[2]], [0, -1, 0], atol=5e-3)</code></pre><p>Finally, we can run the <a href="../../man/benchmarking/#NeuralLyapunov.benchmark"><code>benchmark</code></a> function. For demonstration purposes, we&#39;ll use <code>EnsembleSerial()</code>, which simulates each trajectory without any parallelism when evaluating the trained Lyapunov function and controller. The default <code>ensemble_alg</code> is <a href="https://docs.sciml.ai/DiffEqDocs/dev/features/ensemble/#EnsembleAlgorithms"><code>EnsembleDistributed()</code></a>, which uses <code>pmap</code> internally; see the <a href="https://docs.sciml.ai/DiffEqDocs/stable/features/ensemble/">DifferentialEquations.jl docs</a> for more information and other options. When trajectories are expected to be &quot;quick&quot; (sub-millisecond), multithreading with <a href="https://docs.sciml.ai/DiffEqDocs/dev/features/ensemble/#EnsembleAlgorithms"><code>EnsembleThreads</code></a> is likely preferable. Another option is  <a href="https://docs.sciml.ai/DiffEqGPU/stable/manual/ensemblegpuarray/"><code>EnsembleGPUArray</code></a>, which parallelizes the ODE solves on the GPU. Note that this option is imported from <code>DiffEqGPU</code> and has certain restrictions on the dynamics. For example, the dynamics may not allocate memory (build arrays), so in-place dynamics must be defined in addition to the out-of-place dynamics that NeuralLyapunov usually requires. (Providing both can be achieved by defining both methods for the same function and passing in an <code>ODEFunction</code> made from that function.) For this reason, using <code>EnsembleDistributed()</code> or <code>EnsembleThreads()</code> is recommended, even when training occurs on GPU.</p><pre><code class="language-julia hljs">using OrdinaryDiffEq: EnsembleSerial

benchmarking_results = benchmark(
    open_loop_pendulum_dynamics,
    lb,
    ub,
    spec,
    chain,
    strategy,
    opt;
    simulation_time = 200,
    n = 1000,
    fixed_point = upright_equilibrium,
    p,
    optimization_args,
    state_syms,
    parameter_syms,
    policy_search = true,
    ensemble_alg = EnsembleSerial(),
    endpoint_check,
    init_params = ps,
    init_states = st,
    log_frequency = 1
);</code></pre><p>We can observe the confusion matrix and training time:</p><pre><code class="language-julia hljs">benchmarking_results.confusion_matrix</code></pre><div><div style = "float: left;"><span>4×2 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "columnLabelRow"><th class = "stubheadLabel" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">Classification</th><th style = "text-align: left;">Count</th></tr><tr class = "columnLabelRow"><th class = "stubheadLabel" style = "font-weight: bold; text-align: right;"></th><th title = "String" style = "text-align: left;">String</th><th title = "Int64" style = "text-align: left;">Int64</th></tr></thead><tbody><tr class = "dataRow"><td class = "rowLabel" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: left;">True Positives</td><td style = "text-align: right;">1000</td></tr><tr class = "dataRow"><td class = "rowLabel" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: left;">False Positives</td><td style = "text-align: right;">0</td></tr><tr class = "dataRow"><td class = "rowLabel" style = "font-weight: bold; text-align: right;">3</td><td style = "text-align: left;">True Negatives</td><td style = "text-align: right;">0</td></tr><tr class = "dataRow"><td class = "rowLabel" style = "font-weight: bold; text-align: right;">4</td><td style = "text-align: left;">False Negatives</td><td style = "text-align: right;">0</td></tr></tbody></table></div><pre><code class="language-julia hljs">benchmarking_results.training_time</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">233.52363256</code></pre><p>The <code>benchmark</code> function also outputs a <code>DataFrame</code>, <code>data</code>, with the simulation results. The first three rows are shown below.</p><pre><code class="language-julia hljs">benchmarking_results.data[1:3, :]</code></pre><div><div style = "float: left;"><span>3×7 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "columnLabelRow"><th class = "stubheadLabel" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">Initial State</th><th style = "text-align: left;">Final State</th><th style = "text-align: left;">V</th><th style = "text-align: left;">dVdt</th><th style = "text-align: left;">Predicted in RoA</th><th style = "text-align: left;">Actually in RoA</th><th style = "text-align: left;">Classification</th></tr><tr class = "columnLabelRow"><th class = "stubheadLabel" style = "font-weight: bold; text-align: right;"></th><th title = "SubArray{Float32, 1, Matrix{Float32}, Tuple{Base.Slice{Base.OneTo{Int64}}, Int64}, true}" style = "text-align: left;">SubArray…</th><th title = "Vector{Float32}" style = "text-align: left;">Array…</th><th title = "Float32" style = "text-align: left;">Float32</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Bool" style = "text-align: left;">Bool</th><th title = "Bool" style = "text-align: left;">Bool</th><th title = "String" style = "text-align: left;">String</th></tr></thead><tbody><tr class = "dataRow"><td class = "rowLabel" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: left;">Float32[5.82765, -1.63]</td><td style = "text-align: left;">Float32[3.14217, 1.47443f-8]</td><td style = "text-align: right;">45.7105</td><td style = "text-align: right;">-44.8276</td><td style = "text-align: right;">true</td><td style = "text-align: right;">true</td><td style = "text-align: left;">TP</td></tr><tr class = "dataRow"><td class = "rowLabel" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: left;">Float32[3.57199, 1.782]</td><td style = "text-align: left;">Float32[3.14217, 5.17382f-8]</td><td style = "text-align: right;">13.1541</td><td style = "text-align: right;">-36.7215</td><td style = "text-align: right;">true</td><td style = "text-align: right;">true</td><td style = "text-align: left;">TP</td></tr><tr class = "dataRow"><td class = "rowLabel" style = "font-weight: bold; text-align: right;">3</td><td style = "text-align: left;">Float32[1.86296, -1.206]</td><td style = "text-align: left;">Float32[3.14217, 9.53784f-8]</td><td style = "text-align: right;">23.9957</td><td style = "text-align: right;">-35.8321</td><td style = "text-align: right;">true</td><td style = "text-align: right;">true</td><td style = "text-align: left;">TP</td></tr></tbody></table></div><p>The <code>benchmark</code> function also outputs the Lyapunov function <span>$V$</span> and its time-derivative <span>$V̇$</span>.</p><pre><code class="language-julia hljs">states = benchmarking_results.data[!, &quot;Initial State&quot;]
V_samples = benchmarking_results.data[!, &quot;V&quot;]
all(benchmarking_results.V.(states) .== V_samples)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><pre><code class="language-julia hljs">V̇_samples = benchmarking_results.data[!, &quot;dVdt&quot;]
all(benchmarking_results.V̇.(states) .== V̇_samples)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><p>The &quot;Actually in RoA&quot; column is just the result of applying <code>endpoint_check</code> applied to the &quot;End State&quot; column. The &quot;End State&quot; column is the final state of the simulation starting at that &quot;Initial State&quot;.</p><pre><code class="language-julia hljs">endpoints = benchmarking_results.data[!, &quot;Final State&quot;]
actual = benchmarking_results.data[!, &quot;Actually in RoA&quot;]
all(endpoint_check.(endpoints) .== actual)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><p>Similarly, the labels in the &quot;Predicted in RoA&quot; column are the results of the neural Lyapunov classifier.</p><pre><code class="language-julia hljs">classifier = (V, V̇, x) -&gt; V̇ &lt; zero(V̇) || endpoint_check(x)
predicted = benchmarking_results.data[!, &quot;Predicted in RoA&quot;]
all(classifier.(V_samples, V̇_samples, states) .== predicted)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><p>Finally, the <code>benchmark</code> function also outputs a <code>DataFrame</code>, <code>training_losses</code> with the training loss, sampled every <code>log_frequency</code> iterations:</p><pre><code class="language-julia hljs">benchmarking_results.training_losses[1:3, :]</code></pre><div><div style = "float: left;"><span>3×2 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "columnLabelRow"><th class = "stubheadLabel" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">Iteration</th><th style = "text-align: left;">Loss</th></tr><tr class = "columnLabelRow"><th class = "stubheadLabel" style = "font-weight: bold; text-align: right;"></th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Float32" style = "text-align: left;">Float32</th></tr></thead><tbody><tr class = "dataRow"><td class = "rowLabel" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: right;">2</td><td style = "text-align: right;">10.9832</td></tr><tr class = "dataRow"><td class = "rowLabel" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: right;">3</td><td style = "text-align: right;">31.689</td></tr><tr class = "dataRow"><td class = "rowLabel" style = "font-weight: bold; text-align: right;">3</td><td style = "text-align: right;">4</td><td style = "text-align: right;">27.8765</td></tr></tbody></table></div><pre><code class="language-julia hljs">using Plots

plot(
    benchmarking_results.training_losses.Iteration,
    benchmarking_results.training_losses.Loss,
    yaxis = :log,
    xlabel = &quot;Iteration&quot;,
    ylabel = &quot;Loss&quot;,
    title = &quot;Training Loss&quot;,
    legend = false
)</code></pre><img src="e6b0631f.svg" alt="Example block output"/></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../policy_search/">« Policy Search on the Driven Inverted Pendulum</a><a class="docs-footer-nextpage" href="../../lib/">NeuralLyapunovProblemLibrary.jl »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Thursday 15 January 2026 04:17">Thursday 15 January 2026</span>. Using Julia version 1.11.8.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
