<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Training for Region of Attraction Identification · NeuralLyapunov.jl</title><meta name="title" content="Training for Region of Attraction Identification · NeuralLyapunov.jl"/><meta property="og:title" content="Training for Region of Attraction Identification · NeuralLyapunov.jl"/><meta property="twitter:title" content="Training for Region of Attraction Identification · NeuralLyapunov.jl"/><meta name="description" content="Documentation for NeuralLyapunov.jl."/><meta property="og:description" content="Documentation for NeuralLyapunov.jl."/><meta property="twitter:description" content="Documentation for NeuralLyapunov.jl."/><meta property="og:url" content="https://SciML.github.io/NeuralLyapunov.jl/man/roa/"/><meta property="twitter:url" content="https://SciML.github.io/NeuralLyapunov.jl/man/roa/"/><link rel="canonical" href="https://SciML.github.io/NeuralLyapunov.jl/man/roa/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralLyapunov.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../">Components of a Neural Lyapunov Problem</a></li><li><a class="tocitem" href="../pdesystem/">Solving a Neural Lyapunov Problem</a></li><li><a class="tocitem" href="../minimization/">Lyapunov Minimization Condition</a></li><li><a class="tocitem" href="../decrease/">Lyapunov Decrease Condition</a></li><li><a class="tocitem" href="../structure/">Structuring a Neural Lyapunov function</a></li><li class="is-active"><a class="tocitem" href>Training for Region of Attraction Identification</a></li><li><a class="tocitem" href="../policy_search/">Policy Search and Network-Dependent Dynamics</a></li><li><a class="tocitem" href="../local_lyapunov/">Local Lyapunov analysis</a></li></ul></li><li><span class="tocitem">Demonstrations</span><ul><li><a class="tocitem" href="../../demos/damped_SHO/">Damped Simple Harmonic Oscillator</a></li><li><a class="tocitem" href="../../demos/roa_estimation/">Estimating the Region of Attraction</a></li><li><a class="tocitem" href="../../demos/policy_search/">Policy Search on the Driven Inverted Pendulum</a></li><li><a class="tocitem" href="../../demos/benchmarking/">Benchmarking a neural Lyapunov method</a></li></ul></li><li><span class="tocitem">Test Problem Library</span><ul><li><a class="tocitem" href="../../lib/">NeuralLyapunovProblemLibrary.jl</a></li><li><a class="tocitem" href="../../lib/pendulum/">Pendulum Model</a></li><li><a class="tocitem" href="../../lib/double_pendulum/">Double Pendulum Model</a></li><li><a class="tocitem" href="../../lib/quadrotor/">Quadrotor Models</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manual</a></li><li class="is-active"><a href>Training for Region of Attraction Identification</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Training for Region of Attraction Identification</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/NeuralLyapunov.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/NeuralLyapunov.jl/blob/master/docs/src/man/roa.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Training-for-Region-of-Attraction-Identification"><a class="docs-heading-anchor" href="#Training-for-Region-of-Attraction-Identification">Training for Region of Attraction Identification</a><a id="Training-for-Region-of-Attraction-Identification-1"></a><a class="docs-heading-anchor-permalink" href="#Training-for-Region-of-Attraction-Identification" title="Permalink"></a></h1><p>Satisfying the <a href="../minimization/">minimization</a> and <a href="../decrease/">decrease</a> conditions within the training region (or any region around the fixed point, however small) is sufficient for proving local stability. In many cases, however, we desire an estimate of the region of attraction, rather than simply a guarantee of local stability.</p><p>Any compact sublevel set wherein the minimization and decrease conditions are satisfied is an inner estimate of the region of attraction. Therefore, we can restrict training for those conditions to only within a predetermined sublevel set <span>$\{ x : V(x) \le \rho \}$</span>. To do so, define a <a href="../decrease/#NeuralLyapunov.LyapunovDecreaseCondition"><code>LyapunovDecreaseCondition</code></a> as usual and then pass it through the <a href="#NeuralLyapunov.make_RoA_aware"><code>make_RoA_aware</code></a> function, which returns an analogous <a href="#NeuralLyapunov.RoAAwareDecreaseCondition"><code>RoAAwareDecreaseCondition</code></a>.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.make_RoA_aware" href="#NeuralLyapunov.make_RoA_aware"><code>NeuralLyapunov.make_RoA_aware</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">make_RoA_aware(cond; ρ, out_of_RoA_penalty, sigmoid)</code></pre><p>Add awareness of the region of attraction (RoA) estimation task to the supplied <a href="../decrease/#NeuralLyapunov.LyapunovDecreaseCondition"><code>LyapunovDecreaseCondition</code></a>.</p><p>When estimating the region of attraction using a Lyapunov function, the decrease condition only needs to be met within a bounded sublevel set <span>$\{ x : V(x) ≤ ρ \}$</span>. The returned <a href="#NeuralLyapunov.RoAAwareDecreaseCondition"><code>RoAAwareDecreaseCondition</code></a> enforces the decrease condition represented by <code>cond</code> only in that sublevel set.</p><p><strong>Arguments</strong></p><ul><li><code>cond::LyapunovDecreaseCondition</code>: specifies the loss to be applied when <span>$V(x) ≤ ρ$</span>.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>ρ</code>: the target level such that the RoA will be <span>$\{ x : V(x) ≤ ρ \}$</span>, defaults to 1.</li><li><code>out_of_RoA_penalty::Function</code>: specifies the loss to be applied when <span>$V(x) &gt; ρ$</span>, defaults to no loss.</li><li><code>sigmoid::Function</code>: approximately one when the input is positive and approximately zero when the input is negative, defaults to unit step function.</li></ul><p>The loss applied to samples <span>$x$</span> such that <span>$V(x) &gt; ρ$</span> is <span>$\lvert \texttt{out\_of\_RoA\_penalty}(V(x), V̇(x), x, x_0, ρ) \rvert^2$</span>.</p><p>The <code>sigmoid</code> function allows for a smooth transition between the <span>$V(x) ≤ ρ$</span> case and the <span>$V(x) &gt; ρ$</span> case, by combining the above equations into one:</p><p><span>$\texttt{sigmoid}(ρ - V(x)) (\text{in-RoA expression}) + \texttt{sigmoid}(V(x) - ρ) (\text{out-of-RoA expression}) = 0$</span>.</p><p>Note that a hard transition, which only enforces the in-RoA equation when <span>$V(x) ≤ ρ$</span> and the out-of-RoA equation when <span>$V(x) &gt; ρ$</span> can be provided by a <code>sigmoid</code> which is exactly one when the input is nonnegative and exactly zero when the input is negative. As such, the default value is <code>sigmoid(t) = t ≥ zero(t)</code>.</p><p>See also: <a href="#NeuralLyapunov.RoAAwareDecreaseCondition"><code>RoAAwareDecreaseCondition</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/132d709f59d7107605eb972921a7c286929f65ce/src/decrease_conditions_RoA_aware.jl#L121-L156">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.RoAAwareDecreaseCondition" href="#NeuralLyapunov.RoAAwareDecreaseCondition"><code>NeuralLyapunov.RoAAwareDecreaseCondition</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">RoAAwareDecreaseCondition(check_decrease, rate_metric, strength, rectifier, ρ, out_of_RoA_penalty)</code></pre><p>Specifies the form of the Lyapunov decrease condition to be used, training for a region of attraction estimate of <span>$\{ x : V(x) ≤ ρ \}$</span>.</p><p><strong>Fields</strong></p><ul><li><code>check_decrease::Bool</code>: whether or not to train for negativity/nonpositivity of <span>$V̇(x)$</span>.</li><li><code>rate_metric::Function</code>: should increase with <span>$V̇(x)$</span>; used when <code>check_decrease == true</code>.</li><li><code>strength::Function</code>: specifies the level of strictness for negativity training; should be zero when the two inputs are equal and nonnegative otherwise; used when <code>check_decrease == true</code>.</li><li><code>rectifier::Function</code>: positive when the input is positive and (approximately) zero when the input is negative.</li><li><code>sigmoid::Function</code>: approximately one when the input is positive and approximately zero when the input is negative.</li><li><code>ρ</code>: the level of the sublevel set forming the estimate of the region of attraction.</li><li><code>out_of_RoA_penalty::Function</code>: a loss function to be applied penalizing points outside the sublevel set forming the region of attraction estimate.</li></ul><p><strong>Training conditions</strong></p><p>If <code>check_decrease == true</code>, training will attempt to enforce</p><p><span>$\texttt{rate\_metric}(V(x), V̇(x)) ≤ - \texttt{strength}(x, x_0)$</span></p><p>whenever <span>$V(x) ≤ ρ$</span>, and will instead apply a loss of</p><p><span>$\lvert \texttt{out\_of\_RoA\_penalty}(V(x), V̇(x), x, x_0, ρ) \rvert^2$</span></p><p>when <span>$V(x) &gt; ρ$</span>.</p><p>The inequality will be approximated by the equation</p><p><span>$\texttt{rectifier}(\texttt{rate\_metric}(V(x), V̇(x)) + \texttt{strength}(x, x_0)) = 0$</span>.</p><p>Note that the approximate equation and inequality are identical when <span>$\texttt{rectifier}(t) = \max(0, t)$</span>.</p><p>The <code>sigmoid</code> function allows for a smooth transition between the <span>$V(x) ≤ ρ$</span> case and the <span>$V(x) &gt; ρ$</span> case, by combining the above equations into one:</p><p><span>$\texttt{sigmoid}(ρ - V(x)) (\text{in-RoA expression}) + \texttt{sigmoid}(V(x) - ρ) (\text{out-of-RoA expression}) = 0$</span>.</p><p>Note that a hard transition, which only enforces the in-RoA equation when <span>$V(x) ≤ ρ$</span> and the out-of-RoA equation when <span>$V(x) &gt; ρ$</span> can be provided by a <code>sigmoid</code> which is exactly one when the input is nonnegative and exactly zero when the input is negative.</p><p>If the dynamics truly have a fixed point at <span>$x_0$</span> and <span>$V̇(x)$</span> is truly the rate of decrease of <span>$V(x)$</span> along the dynamics, then <span>$V̇(x_0)$</span> will be <span>$0$</span> and there is no need to train for <span>$V̇(x_0) = 0$</span>.</p><p><strong>Examples:</strong></p><p>Asymptotic decrease can be enforced by requiring     <span>$V̇(x) ≤ -C \lVert x - x_0 \rVert^2$</span>, for some positive <span>$C$</span>, which corresponds to</p><pre><code class="nohighlight hljs">rate_metric = (V, dVdt) -&gt; dVdt
strength = (x, x0) -&gt; C * (x - x0) ⋅ (x - x0)</code></pre><p>Exponential decrease of rate <span>$k$</span> is proven by     <span>$V̇(x) ≤ - k V(x)$</span>, which corresponds to</p><pre><code class="nohighlight hljs">rate_metric = (V, dVdt) -&gt; dVdt + k * V
strength = (x, x0) -&gt; 0.0</code></pre><p>Enforcing either condition only in the region of attraction and not penalizing any points outside that region would correspond to</p><pre><code class="nohighlight hljs">out_of_RoA_penalty = (V, dVdt, state, fixed_point, ρ) -&gt; 0.0</code></pre><p>whereas an example of a penalty that decays farther in state space from the fixed point is</p><pre><code class="nohighlight hljs">out_of_RoA_penalty = (V, dVdt, x, x0, ρ) -&gt; 1.0 / ((x - x0) ⋅ (x - x0))</code></pre><p>Note that this penalty could also depend on values of <span>$V$</span> and <span>$V̇$</span> at various points, as well as <span>$ρ$</span>.</p><p>In any of these cases, the rectified linear unit <code>rectifier = (t) -&gt; max(zero(t), t)</code> exactly represents the inequality, but differentiable approximations of this function may be employed.</p><p>See also: <a href="../decrease/#NeuralLyapunov.LyapunovDecreaseCondition"><code>LyapunovDecreaseCondition</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/132d709f59d7107605eb972921a7c286929f65ce/src/decrease_conditions_RoA_aware.jl#L1-L88">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../structure/">« Structuring a Neural Lyapunov function</a><a class="docs-footer-nextpage" href="../policy_search/">Policy Search and Network-Dependent Dynamics »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.9.0 on <span class="colophon-date" title="Monday 17 March 2025 17:43">Monday 17 March 2025</span>. Using Julia version 1.11.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
