<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · NeuralLyapunov.jl</title><meta name="title" content="Home · NeuralLyapunov.jl"/><meta property="og:title" content="Home · NeuralLyapunov.jl"/><meta property="twitter:title" content="Home · NeuralLyapunov.jl"/><meta name="description" content="Documentation for NeuralLyapunov.jl."/><meta property="og:description" content="Documentation for NeuralLyapunov.jl."/><meta property="twitter:description" content="Documentation for NeuralLyapunov.jl."/><meta property="og:url" content="https://SciML.github.io/NeuralLyapunov.jl/"/><meta property="twitter:url" content="https://SciML.github.io/NeuralLyapunov.jl/"/><link rel="canonical" href="https://SciML.github.io/NeuralLyapunov.jl/"/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>NeuralLyapunov.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/NeuralLyapunov.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/NeuralLyapunov.jl/blob/master/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="NeuralLyapunov"><a class="docs-heading-anchor" href="#NeuralLyapunov">NeuralLyapunov</a><a id="NeuralLyapunov-1"></a><a class="docs-heading-anchor-permalink" href="#NeuralLyapunov" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/SciML/NeuralLyapunov.jl">NeuralLyapunov</a>.</p><ul><li><a href="#NeuralLyapunov.AbstractLyapunovDecreaseCondition"><code>NeuralLyapunov.AbstractLyapunovDecreaseCondition</code></a></li><li><a href="#NeuralLyapunov.AbstractLyapunovMinimizationCondition"><code>NeuralLyapunov.AbstractLyapunovMinimizationCondition</code></a></li><li><a href="#NeuralLyapunov.LyapunovDecreaseCondition"><code>NeuralLyapunov.LyapunovDecreaseCondition</code></a></li><li><a href="#NeuralLyapunov.LyapunovMinimizationCondition"><code>NeuralLyapunov.LyapunovMinimizationCondition</code></a></li><li><a href="#NeuralLyapunov.NeuralLyapunovSpecification"><code>NeuralLyapunov.NeuralLyapunovSpecification</code></a></li><li><a href="#NeuralLyapunov.NeuralLyapunovStructure"><code>NeuralLyapunov.NeuralLyapunovStructure</code></a></li><li><a href="#NeuralLyapunov.RoAAwareDecreaseCondition"><code>NeuralLyapunov.RoAAwareDecreaseCondition</code></a></li><li><a href="#NeuralLyapunov.AsymptoticDecrease-Tuple{}"><code>NeuralLyapunov.AsymptoticDecrease</code></a></li><li><a href="#NeuralLyapunov.DontCheckDecrease-Tuple{}"><code>NeuralLyapunov.DontCheckDecrease</code></a></li><li><a href="#NeuralLyapunov.DontCheckNonnegativity-Tuple{}"><code>NeuralLyapunov.DontCheckNonnegativity</code></a></li><li><a href="#NeuralLyapunov.ExponentialDecrease-Tuple{Real}"><code>NeuralLyapunov.ExponentialDecrease</code></a></li><li><a href="#NeuralLyapunov.NeuralLyapunovPDESystem-Tuple{Function, Any, Any, NeuralLyapunovSpecification}"><code>NeuralLyapunov.NeuralLyapunovPDESystem</code></a></li><li><a href="#NeuralLyapunov.NonnegativeNeuralLyapunov-Tuple{Integer}"><code>NeuralLyapunov.NonnegativeNeuralLyapunov</code></a></li><li><a href="#NeuralLyapunov.PositiveSemiDefinite-Tuple{}"><code>NeuralLyapunov.PositiveSemiDefinite</code></a></li><li><a href="#NeuralLyapunov.PositiveSemiDefiniteStructure-Tuple{Integer}"><code>NeuralLyapunov.PositiveSemiDefiniteStructure</code></a></li><li><a href="#NeuralLyapunov.StrictlyPositiveDefinite-Tuple{}"><code>NeuralLyapunov.StrictlyPositiveDefinite</code></a></li><li><a href="#NeuralLyapunov.UnstructuredNeuralLyapunov-Tuple{}"><code>NeuralLyapunov.UnstructuredNeuralLyapunov</code></a></li><li><a href="#NeuralLyapunov.add_policy_search-Tuple{NeuralLyapunovStructure, Integer}"><code>NeuralLyapunov.add_policy_search</code></a></li><li><a href="#NeuralLyapunov.check_decrease-Tuple{NeuralLyapunov.AbstractLyapunovDecreaseCondition}"><code>NeuralLyapunov.check_decrease</code></a></li><li><a href="#NeuralLyapunov.check_minimal_fixed_point-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}"><code>NeuralLyapunov.check_minimal_fixed_point</code></a></li><li><a href="#NeuralLyapunov.check_nonnegativity-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}"><code>NeuralLyapunov.check_nonnegativity</code></a></li><li><a href="#NeuralLyapunov.get_decrease_condition-Tuple{NeuralLyapunov.AbstractLyapunovDecreaseCondition}"><code>NeuralLyapunov.get_decrease_condition</code></a></li><li><a href="#NeuralLyapunov.get_minimization_condition-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}"><code>NeuralLyapunov.get_minimization_condition</code></a></li><li><a href="#NeuralLyapunov.get_numerical_lyapunov_function-Tuple{Any, Any, NeuralLyapunovStructure, Function, Any}"><code>NeuralLyapunov.get_numerical_lyapunov_function</code></a></li><li><a href="#NeuralLyapunov.get_policy-Tuple{Any, Any, Integer, Integer}"><code>NeuralLyapunov.get_policy</code></a></li><li><a href="#NeuralLyapunov.local_lyapunov-Union{Tuple{T}, Tuple{Function, Any, Any, AbstractMatrix{T}}} where T&lt;:Number"><code>NeuralLyapunov.local_lyapunov</code></a></li><li><a href="#NeuralLyapunov.make_RoA_aware-Tuple{LyapunovDecreaseCondition}"><code>NeuralLyapunov.make_RoA_aware</code></a></li><li><a href="#NeuralLyapunov.phi_to_net-Tuple{Any, Any}"><code>NeuralLyapunov.phi_to_net</code></a></li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.AbstractLyapunovDecreaseCondition" href="#NeuralLyapunov.AbstractLyapunovDecreaseCondition"><code>NeuralLyapunov.AbstractLyapunovDecreaseCondition</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractLyapunovDecreaseCondition</code></pre><p>Represents the decrease condition in a neural Lyapunov problem</p><p>All concrete <code>AbstractLyapunovDecreaseCondition</code> subtypes should define the <code>check_decrease</code> and <code>get_decrease_condition</code> functions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/conditions_specification.jl#L38-L45">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.AbstractLyapunovMinimizationCondition" href="#NeuralLyapunov.AbstractLyapunovMinimizationCondition"><code>NeuralLyapunov.AbstractLyapunovMinimizationCondition</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractLyapunovMinimizationCondition</code></pre><p>Represents the minimization condition in a neural Lyapunov problem</p><p>All concrete <code>AbstractLyapunovMinimizationCondition</code> subtypes should define the <code>check_nonnegativity</code>, <code>check_fixed_point</code>, and <code>get_minimization_condition</code> functions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/conditions_specification.jl#L28-L35">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.LyapunovDecreaseCondition" href="#NeuralLyapunov.LyapunovDecreaseCondition"><code>NeuralLyapunov.LyapunovDecreaseCondition</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LyapunovDecreaseCondition(check_decrease, decrease, strength, rectifier)</code></pre><p>Specifies the form of the Lyapunov conditions to be used; if <code>check_decrease</code>, training will enforce <code>decrease(V, dVdt) ≤ strength(state, fixed_point)</code>.</p><p>The inequality will be approximated by the equation     <code>rectifier(decrease(V, dVdt) - strength(state, fixed_point)) = 0.0</code>.</p><p>If the dynamics truly have a fixed point at <code>fixed_point</code> and <code>dVdt</code> has been defined properly in terms of the dynamics, then <code>dVdt(fixed_point)</code> will be <code>0</code> and there is no need to enforce <code>dVdt(fixed_point) = 0</code>, so <code>check_fixed_point</code> defaults to <code>false</code>.</p><p><strong>Examples:</strong></p><p>Asymptotic decrease can be enforced by requiring     <code>dVdt ≤ -C |state - fixed_point|^2</code>, which corresponds to     <code>decrease = (V, dVdt) -&gt; dVdt</code>     <code>strength = (x, x0) -&gt; -C * (x - x0) ⋅ (x - x0)</code></p><p>Exponential decrease of rate <code>k</code> is proven by <code>dVdt ≤ - k * V</code>, so corresponds to     <code>decrease = (V, dVdt) -&gt; dVdt + k * V</code>     <code>strength = (x, x0) -&gt; 0.0</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/decrease_conditions.jl#L1-L25">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.LyapunovMinimizationCondition" href="#NeuralLyapunov.LyapunovMinimizationCondition"><code>NeuralLyapunov.LyapunovMinimizationCondition</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LyapunovMinimizationCondition</code></pre><p>Specifies the form of the Lyapunov conditions to be used.</p><p>If <code>check_nonnegativity</code> is <code>true</code>, training will attempt to enforce     <code>V(state) ≥ strength(state, fixed_point)</code>. The inequality will be approximated by the equation     <code>rectifier(strength(state, fixed_point) - V(state)) = 0.0</code>. If <code>check_fixed_point</code> is <code>true</code>, then training will also attempt to enforce     <code>V(fixed_point) = 0</code>.</p><p><strong>Examples</strong></p><p>The condition that the Lyapunov function must be minimized uniquely at the fixed point can be represented as <code>V(fixed_point) = 0</code>, <code>V(state) &gt; 0</code> when <code>state ≠ fixed_point</code>. This could be enfored by <code>V(fixed_point) ≥ ||state - fixed_point||^2</code>, which would be represented, with <code>check_nonnegativity = true</code>, by     strength(state, fixed<em>point) = ||state - fixed</em>point||^2, paired with <code>V(fixed_point) = 0</code>, which can be enforced with <code>check_fixed_point = true</code>.</p><p>If <code>V</code> were structured such that it is always nonnegative, then <code>V(fixed_point) = 0</code> is all that must be enforced in training for the Lyapunov function to be uniquely minimized at <code>fixed_point</code>. So, in that case, we would use     <code>check_nonnegativity = false;  check_fixed_point = true</code>.</p><p>In either case, <code>rectifier = (t) -&gt; max(0.0, t)</code> exactly represents the inequality, but differentiable approximations of this function may be employed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/minimization_conditions.jl#L1-L29">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.NeuralLyapunovSpecification" href="#NeuralLyapunov.NeuralLyapunovSpecification"><code>NeuralLyapunov.NeuralLyapunovSpecification</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NeuralLyapunovSpecification</code></pre><p>Specifies a neural Lyapunov problem</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/conditions_specification.jl#L48-L52">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.NeuralLyapunovStructure" href="#NeuralLyapunov.NeuralLyapunovStructure"><code>NeuralLyapunov.NeuralLyapunovStructure</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NeuralLyapunovStructure</code></pre><p>Specifies the structure of the neural Lyapunov function and its derivative.</p><p>Allows the user to define the Lyapunov in terms of the neural network to structurally enforce Lyapunov conditions. <code>V(phi::Function, state, fixed_point)</code> takes in the neural network, the state, and the fixed point, and outputs the value of the Lyapunov function at <code>state</code>. <code>V̇(phi::Function, J_phi::Function, f::Function, state, params, t, fixed_point)</code> takes in the neural network, jacobian of the neural network, dynamics, state, parameters and time (for calling the dynamics, when relevant), and fixed point, and outputs the time derivative of the Lyapunov function at <code>state</code>. <code>f_call(dynamics::Function, phi::Function, state, p, t)</code> takes in the dynamics, the neural network, the state, the parameters of the dynamics, and time, and outputs the derivative of the state; this is useful for making closed-loop dynamics which depend on the neural network, such as in the policy search case <code>network_dim</code> is the dimension of the output of the neural network.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/conditions_specification.jl#L1-L19">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.RoAAwareDecreaseCondition" href="#NeuralLyapunov.RoAAwareDecreaseCondition"><code>NeuralLyapunov.RoAAwareDecreaseCondition</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RoAAwareDecreaseCondition(check_decrease, decrease, strength, rectifier, ρ,
                          out_of_RoA_penalty)</code></pre><p>Specifies the form of the Lyapunov conditions to be used, training for a region of attraction estimate of <code>{ x : V(x) ≤ ρ }</code></p><p>If <code>check_decrease</code>, training will enforce <code>decrease(V(state), dVdt(state)) ≤ strength(state, fixed_point)</code> whenever <code>V(state) ≤ ρ</code>, and will instead apply <code>|out_of_RoA_penalty(V(state), dVdt(state), state, fixed_point, ρ)|^2</code> when <code>V(state) &gt; ρ</code>.</p><p>The inequality will be approximated by the equation     <code>rectifier(decrease(V(state), dVdt(state)) - strength(state, fixed_point)) = 0.0</code>.</p><p>If the dynamics truly have a fixed point at <code>fixed_point</code> and <code>dVdt</code> has been defined properly in terms of the dynamics, then <code>dVdt(fixed_point)</code> will be <code>0</code> and there is no need to enforce <code>dVdt(fixed_point) = 0</code>, so <code>check_fixed_point</code> defaults to <code>false</code>.</p><p><strong>Examples:</strong></p><p>Asymptotic decrease can be enforced by requiring     <code>dVdt ≤ -C |state - fixed_point|^2</code>, which corresponds to     <code>decrease = (V, dVdt) -&gt; dVdt</code> and     <code>strength = (x, x0) -&gt; -C * (x - x0) ⋅ (x - x0)</code>.</p><p>Exponential decrease of rate <code>k</code> is proven by <code>dVdt ≤ - k * V</code>, so corresponds to     <code>decrease = (V, dVdt) -&gt; dVdt + k * V</code> and     <code>strength = (x, x0) -&gt; 0.0</code>.</p><p>Enforcing either condition only in the region of attraction and not penalizing any points outside that region would correspond to     <code>out_of_RoA_penalty = (V, dVdt, state, fixed_point, ρ) -&gt; 0.0</code>, whereas an example of a penalty that decays farther in state space from the fixed point is     <code>out_of_RoA_penalty = (V, dVdt, state, fixed_point, ρ) -&gt; 1.0 / ((x - x0) ⋅ (x - x0))</code>. Note that this penalty could also depend on values of <code>V</code>, <code>dVdt</code>, and <code>ρ</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/decrease_conditions_RoA_aware.jl#L1-L38">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.AsymptoticDecrease-Tuple{}" href="#NeuralLyapunov.AsymptoticDecrease-Tuple{}"><code>NeuralLyapunov.AsymptoticDecrease</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">AsymptoticDecrease(; strict, C, rectifier)</code></pre><p>Construct a <code>LyapunovDecreaseCondition</code> corresponding to asymptotic decrease.</p><p>If <code>strict</code> is <code>false</code>, the condition is <code>dV/dt ≤ 0</code>, and if <code>strict</code> is <code>true</code>, the condition is <code>dV/dt ≤ - C | state - fixed_point |^2</code>.</p><p>The inequality is represented by <code>a ≥ b</code> &lt;==&gt; <code>rectifier(b-a) = 0.0</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/decrease_conditions.jl#L47-L56">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.DontCheckDecrease-Tuple{}" href="#NeuralLyapunov.DontCheckDecrease-Tuple{}"><code>NeuralLyapunov.DontCheckDecrease</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">DontCheckDecrease()</code></pre><p>Construct a <code>LyapunovDecreaseCondition</code> which represents not checking for decrease of the Lyapunov function along system trajectories. This is appropriate in cases when the Lyapunov decrease condition has been structurally enforced.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/decrease_conditions.jl#L106-L112">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.DontCheckNonnegativity-Tuple{}" href="#NeuralLyapunov.DontCheckNonnegativity-Tuple{}"><code>NeuralLyapunov.DontCheckNonnegativity</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">DontCheckNonnegativity(check_fixed_point)</code></pre><p>Construct a <code>LyapunovMinimizationCondition</code> which represents not checking for nonnegativity of the Lyapunov function. This is appropriate in cases where this condition has been structurally enforced.</p><p>It is still possible to check for <code>V(fixed_point) = 0</code>, even in this case, for example if <code>V</code> is structured to be positive for <code>state ≠ fixed_point</code>, but it is not guaranteed structurally that <code>V(fixed_point) = 0</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/minimization_conditions.jl#L98-L108">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.ExponentialDecrease-Tuple{Real}" href="#NeuralLyapunov.ExponentialDecrease-Tuple{Real}"><code>NeuralLyapunov.ExponentialDecrease</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ExponentialDecrease(k; strict, C, rectifier)</code></pre><p>Construct a <code>LyapunovDecreaseCondition</code> corresponding to exponential decrease of rate <code>k</code>.</p><p>If <code>strict</code> is <code>false</code>, the condition is <code>dV/dt ≤ -k * V</code>, and if <code>strict</code> is <code>true</code>, the condition is <code>dV/dt ≤ -k * V - C * ||state - fixed_point||^2</code>.</p><p>The inequality is represented by <code>a ≥ b</code> &lt;==&gt; <code>rectifier(b-a) = 0.0</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/decrease_conditions.jl#L76-L85">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.NeuralLyapunovPDESystem-Tuple{Function, Any, Any, NeuralLyapunovSpecification}" href="#NeuralLyapunov.NeuralLyapunovPDESystem-Tuple{Function, Any, Any, NeuralLyapunovSpecification}"><code>NeuralLyapunov.NeuralLyapunovPDESystem</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">NeuralLyapunovPDESystem(dynamics::ODESystem, bounds, spec; &lt;keyword_arguments&gt;)
NeuralLyapunovPDESystem(dynamics::Function, lb, ub, spec; &lt;keyword_arguments&gt;)</code></pre><p>Construct a <code>ModelingToolkit.PDESystem</code> representing the specified neural Lyapunov problem.</p><p><strong>Arguments</strong></p><ul><li><code>dynamics</code>: the dynamical system being analyzed, represented as an <code>ODESystem</code> or the       function <code>f</code> such that <code>ẋ = f(x[, u], p, t)</code>; either way, the ODE should not depend       on time and only <code>t = 0.0</code> will be used</li><li><code>bounds</code>: an array of domains, defining the training domain by bounding the states (and       derivatives, when applicable) of <code>dynamics</code>; only used when <code>dynamics isa       ODESystem</code>, otherwise use <code>lb</code> and <code>ub</code>.</li><li><code>lb</code> and <code>ub</code>: the training domain will be <span>$[lb_1, ub_1]×[lb_2, ub_2]×...$</span>; not used       when <code>dynamics isa ODESystem</code>, then use <code>bounds</code>.</li><li><code>spec::NeuralLyapunovSpecification</code>: defines the Lyapunov function structure, as well as       the minimization and decrease conditions.</li><li><code>fixed_point</code>: the equilibrium being analyzed; defaults to the origin.</li><li><code>p</code>: the values of the parameters of the dynamical system being analyzed; defaults to       <code>SciMLBase.NullParameters()</code>; not used when <code>dynamics isa ODESystem</code>, then use the       default parameter values of <code>dynamics</code>.</li><li><code>state_syms</code>: an array of the <code>Symbol</code> representing each state; not used when <code>dynamics       isa ODESystem</code>, then the symbols from <code>dynamics</code> are used; if <code>dynamics isa       ODEFunction</code>, symbols stored there are used, unless overridden here; if not provided       here and cannot be inferred, <code>[:state1, :state2, ...]</code> will be used.</li><li><code>parameter_syms</code>: an array of the <code>Symbol</code> representing each parameter; not used when       <code>dynamics isa ODESystem</code>, then the symbols from <code>dynamics</code> are used; if <code>dynamics       isa ODEFunction</code>, symbols stored there are used, unless overridden here; if not       provided here and cannot be inferred, <code>[:param1, :param2, ...]</code> will be used.</li><li><code>policy_search::Bool</code>: whether or not to include a loss term enforcing <code>fixed_point</code> to       actually be a fixed point; defaults to <code>false</code>; only used when <code>dynamics isa       Function &amp;&amp; !(dynamics isa ODEFunction)</code>; when <code>dynamics isa ODEFunction</code>,       <code>policy_search</code> must be <code>false</code>, so should not be supplied; when <code>dynamics isa       ODESystem</code>, value inferred by the presence of unbound inputs.</li><li><code>name</code>: the name of the constructed <code>PDESystem</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/NeuralLyapunovPDESystem.jl#L1-L36">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.NonnegativeNeuralLyapunov-Tuple{Integer}" href="#NeuralLyapunov.NonnegativeNeuralLyapunov-Tuple{Integer}"><code>NeuralLyapunov.NonnegativeNeuralLyapunov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">NonnegativeNeuralLyapunov(network_dim, δ, pos_def; grad_pos_def, grad)</code></pre><p>Create a <code>NeuralLyapunovStructure</code> where the Lyapunov function is the L2 norm of the neural network output plus a constant δ times a function <code>pos_def</code>.</p><p>The condition that the Lyapunov function must be minimized uniquely at the fixed point can be represented as <code>V(fixed_point) = 0</code>, <code>V(state) &gt; 0</code> when <code>state ≠ fixed_point</code>. This structure ensures <code>V(state) ≥ 0</code>. Further, if <code>δ &gt; 0</code> and <code>pos_def(fixed_point, fixed_point) = 0</code>, but <code>pos_def(state, fixed_point) &gt; 0</code> when <code>state ≠ fixed_point</code>, this ensures that <code>V(state) &gt; 0</code> when <code>state != fixed_point</code>. This does not enforce <code>V(fixed_point) = 0</code>, so that condition must included in the neural Lyapunov loss function.</p><p><code>grad_pos_def(state, fixed_point)</code> should be the gradient of <code>pos_def</code> with respect to <code>state</code> at <code>state</code>. If <code>grad_pos_def</code> is not defined, it is evaluated using <code>grad</code>, which defaults to <code>ForwardDiff.gradient</code>.</p><p>The neural network output has dimension <code>network_dim</code>.</p><p>Dynamics are assumed to be in <code>f(state, p, t)</code> form, as in an <code>ODEFunction</code>. For <code>f(state, input, p, t)</code>, consider using <code>add_policy_search</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/structure_specification.jl#L21-L43">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.PositiveSemiDefinite-Tuple{}" href="#NeuralLyapunov.PositiveSemiDefinite-Tuple{}"><code>NeuralLyapunov.PositiveSemiDefinite</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">PositiveSemiDefinite(check_fixed_point)</code></pre><p>Construct a <code>LyapunovMinimizationCondition</code> representing     <code>V(state) ≥ 0</code>. If <code>check_fixed_point</code> is <code>true</code>, then training will also attempt to enforce     <code>V(fixed_point) = 0</code>.</p><p>The inequality is represented by <code>a ≥ b</code> &lt;==&gt; <code>rectifier(b-a) = 0.0</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/minimization_conditions.jl#L76-L85">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.PositiveSemiDefiniteStructure-Tuple{Integer}" href="#NeuralLyapunov.PositiveSemiDefiniteStructure-Tuple{Integer}"><code>NeuralLyapunov.PositiveSemiDefiniteStructure</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">PositiveSemiDefiniteStructure(network_dim; pos_def, non_neg, grad_pos_def, grad_non_neg, grad)</code></pre><p>Create a <code>NeuralLyapunovStructure</code> where the Lyapunov function is the product of a positive (semi-)definite function <code>pos_def</code> which does not depend on the network and a nonnegative function non_neg which does depend the network.</p><p>The condition that the Lyapunov function must be minimized uniquely at the fixed point can be represented as <code>V(fixed_point) = 0</code>, <code>V(state) &gt; 0</code> when <code>state ≠ fixed_point</code>. This structure ensures <code>V(state) ≥ 0</code>. Further, if <code>pos_def</code> is <code>0</code> only at <code>fixed_point</code> (and positive elsewhere) and if <code>non_neg</code> is strictly positive away from <code>fixed_point</code> (as is the case for the default values of <code>pos_def</code> and <code>non_neg</code>), then this structure ensures <code>V(fixed_point) = 0</code> and <code>V(state) &gt; 0</code> when <code>state ≠ fixed_point</code>.</p><p><code>grad_pos_def(state, fixed_point)</code> should be the gradient of <code>pos_def</code> with respect to <code>state</code> at <code>state</code>. Similarly, <code>grad_non_neg(net, J_net, state, fixed_point)</code> should be the gradient of <code>non_neg(net, state, fixed_point)</code> with respect to <code>state</code> at <code>state</code>. If <code>grad_pos_def</code> or <code>grad_non_neg</code> is not defined, it is evaluated using <code>grad</code>, which defaults to <code>ForwardDiff.gradient</code>.</p><p>The neural network output has dimension <code>network_dim</code>.</p><p>Dynamics are assumed to be in <code>f(state, p, t)</code> form, as in an <code>ODEFunction</code>. For <code>f(state, input, p, t)</code>, consider using <code>add_policy_search</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/structure_specification.jl#L85-L109">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.StrictlyPositiveDefinite-Tuple{}" href="#NeuralLyapunov.StrictlyPositiveDefinite-Tuple{}"><code>NeuralLyapunov.StrictlyPositiveDefinite</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">StrictlyPositiveDefinite(C; check_fixed_point, rectifier)</code></pre><p>Construct a <code>LyapunovMinimizationCondition</code> representing     <code>V(state) ≥ C * ||state - fixed_point||^2</code>. If <code>check_fixed_point</code> is <code>true</code>, then training will also attempt to enforce     <code>V(fixed_point) = 0</code>.</p><p>The inequality is represented by <code>a ≥ b</code> &lt;==&gt; <code>rectifier(b-a) = 0.0</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/minimization_conditions.jl#L53-L62">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.UnstructuredNeuralLyapunov-Tuple{}" href="#NeuralLyapunov.UnstructuredNeuralLyapunov-Tuple{}"><code>NeuralLyapunov.UnstructuredNeuralLyapunov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">UnstructuredNeuralLyapunov()</code></pre><p>Create a <code>NeuralLyapunovStructure</code> where the Lyapunov function is the neural network evaluated at the state. This does not structurally enforce any Lyapunov conditions.</p><p>Dynamics are assumed to be in <code>f(state, p, t)</code> form, as in an <code>ODEFunction</code>. For <code>f(state, input, p, t)</code>, consider using <code>add_policy_search</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/structure_specification.jl#L1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.add_policy_search-Tuple{NeuralLyapunovStructure, Integer}" href="#NeuralLyapunov.add_policy_search-Tuple{NeuralLyapunovStructure, Integer}"><code>NeuralLyapunov.add_policy_search</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">add_policy_search(lyapunov_structure, new_dims, control_structure)</code></pre><p>Add dependence on the neural network to the dynamics in a <code>NeuralLyapunovStructure</code>.</p><p>Add <code>new_dims</code> outputs to the neural network and feeds them through <code>control_structure</code> to calculate the contribution of the neural network to the dynamics. Use the existing <code>lyapunov_structure.network_dim</code> dimensions as in <code>lyapunov_structure</code> to calculate the Lyapunov function.</p><p><code>lyapunov_structure</code> should assume in its <code>V̇</code> that the dynamics take a form <code>f(x, p, t)</code>. The returned <code>NeuralLyapunovStructure</code> will assume instead <code>f(x, u, p, t)</code>, where <code>u</code> is the contribution from the neural network. Therefore, this structure cannot be used with a <code>NeuralLyapunovPDESystem</code> method that requires an <code>ODEFunction</code>, <code>ODESystem</code>, or <code>ODEProblem</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/policy_search.jl#L1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.check_decrease-Tuple{NeuralLyapunov.AbstractLyapunovDecreaseCondition}" href="#NeuralLyapunov.check_decrease-Tuple{NeuralLyapunov.AbstractLyapunovDecreaseCondition}"><code>NeuralLyapunov.check_decrease</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">check_decrease(cond::AbstractLyapunovDecreaseCondition)</code></pre><p>Return <code>true</code> if <code>cond</code> specifies training to meet the Lyapunov decrease condition, and <code>false</code> if <code>cond</code> specifies no training to meet this condition.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/conditions_specification.jl#L92-L97">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.check_minimal_fixed_point-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}" href="#NeuralLyapunov.check_minimal_fixed_point-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}"><code>NeuralLyapunov.check_minimal_fixed_point</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">check_minimal_fixed_point(cond::AbstractLyapunovMinimizationCondition)</code></pre><p>Return <code>true</code> if <code>cond</code> specifies training for the Lyapunov function to equal zero at the fixed point, and <code>false</code> if <code>cond</code> specifies no training to meet this condition.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/conditions_specification.jl#L70-L75">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.check_nonnegativity-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}" href="#NeuralLyapunov.check_nonnegativity-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}"><code>NeuralLyapunov.check_nonnegativity</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">check_nonnegativity(cond::AbstractLyapunovMinimizationCondition)</code></pre><p>Return <code>true</code> if <code>cond</code> specifies training to meet the Lyapunov minimization condition, and <code>false</code> if <code>cond</code> specifies no training to meet this condition.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/conditions_specification.jl#L59-L64">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.get_decrease_condition-Tuple{NeuralLyapunov.AbstractLyapunovDecreaseCondition}" href="#NeuralLyapunov.get_decrease_condition-Tuple{NeuralLyapunov.AbstractLyapunovDecreaseCondition}"><code>NeuralLyapunov.get_decrease_condition</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_decrease_condition(cond::AbstractLyapunovDecreaseCondition)</code></pre><p>Return a function of <code>V</code>, <code>dVdt</code>, <code>state</code>, and <code>fixed_point</code> that is equal to zero when the Lyapunov decrease condition is met and is greater than zero when it is violated.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/conditions_specification.jl#L103-L108">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.get_minimization_condition-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}" href="#NeuralLyapunov.get_minimization_condition-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}"><code>NeuralLyapunov.get_minimization_condition</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_minimization_condition(cond::AbstractLyapunovMinimizationCondition)</code></pre><p>Return a function of <code>V</code>, <code>state</code>, and <code>fixed_point</code> that equals zero when the Lyapunov minimization condition is met and is greater than zero when it&#39;s violated.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/conditions_specification.jl#L81-L86">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.get_numerical_lyapunov_function-Tuple{Any, Any, NeuralLyapunovStructure, Function, Any}" href="#NeuralLyapunov.get_numerical_lyapunov_function-Tuple{Any, Any, NeuralLyapunovStructure, Function, Any}"><code>NeuralLyapunov.get_numerical_lyapunov_function</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_numerical_lyapunov_function(phi, θ, structure, dynamics, fixed_point;
                                &lt;keyword_arguments&gt;)</code></pre><p>Combine Lyapunov function structure, dynamics, and neural network weights to generate Julia functions representing the Lyapunov function and its time derivative: <span>$V(x), V̇(x)$</span>.</p><p>These functions can operate on a state vector or columnwise on a matrix of state vectors.</p><p><strong>Arguments</strong></p><ul><li><code>phi</code>: the neural network, represented as <code>phi(x, θ)</code> if the neural network has a single       output, or a <code>Vector</code> of the same with one entry per neural network output.</li><li><code>θ</code>: the parameters of the neural network; <code>θ[:φ1]</code> should be the parameters of the first       neural network output (even if there is only one), <code>θ[:φ2]</code> the parameters of the       second (if there are multiple), and so on.</li><li><code>structure</code>: a <a href="#NeuralLyapunov.NeuralLyapunovStructure"><code>NeuralLyapunovStructure</code></a> representing the structure of the neural       Lyapunov function.</li><li><code>dynamics</code>: the system dynamics, as a function to be used in conjunction with       <code>structure.f_call</code>.</li><li><code>fixed_point</code>: the equilibrium point being analyzed by the Lyapunov function.</li><li><code>p</code>: parameters to be passed into <code>dynamics</code>; defaults to <code>SciMLBase.NullParameters()</code>.</li><li><code>use_V̇_structure</code>: when <code>true</code>, <span>$V̇(x)$</span> is calculated using <code>structure.V̇</code>; when <code>false</code>,       <span>$V̇(x)$</span> is calculated using <code>deriv</code> as <span>$\frac{d}{dt} V(x + t f(x))$</span> at       <span>$t = 0$</span>; defaults to <code>false</code>, as it is more efficient in many cases.</li><li><code>deriv</code>: a function for calculating derivatives; defaults to (and expects same arguments       as) <code>ForwardDiff.derivative</code>; only used when <code>use_V̇_structure</code> is <code>false</code>.</li><li><code>jac</code>: a function for calculating Jacobians; defaults to (and expects same arguments as)       <code>ForwardDiff.jacobian</code>; only used when <code>use_V̇_structure</code> is <code>true</code>.</li><li><code>J_net</code>: the Jacobian of the neural network, specified as a function       <code>J_net(phi, θ, state)</code>; if <code>isnothing(J_net)</code> (as is the default), <code>J_net</code> will be       calculated using <code>jac</code>; only used when <code>use_V̇_structure</code> is <code>true</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/numerical_lyapunov_functions.jl#L1-L32">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.get_policy-Tuple{Any, Any, Integer, Integer}" href="#NeuralLyapunov.get_policy-Tuple{Any, Any, Integer, Integer}"><code>NeuralLyapunov.get_policy</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_policy(phi, θ, network_func, dim; control_structure)</code></pre><p>Generate a Julia function representing the control policy as a function of the state</p><p>The returned function can operate on a state vector or columnwise on a matrix of state vectors.</p><p><code>phi</code> is the neural network with parameters <code>θ</code>. The network should have <code>network_dim</code> outputs, the last <code>control_dim</code> of which will be passed into <code>control_structure</code> to create the policy output.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/policy_search.jl#L51-L62">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.local_lyapunov-Union{Tuple{T}, Tuple{Function, Any, Any, AbstractMatrix{T}}} where T&lt;:Number" href="#NeuralLyapunov.local_lyapunov-Union{Tuple{T}, Tuple{Function, Any, Any, AbstractMatrix{T}}} where T&lt;:Number"><code>NeuralLyapunov.local_lyapunov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_local_lyapunov(dynamics, state_dim, optimizer_factory[, jac]; fixed_point, p)</code></pre><p>Use semidefinite programming to derive a quadratic Lyapunov function for the linearization of <code>dynamics</code> around <code>fixed_point</code>. Return <code>(V, dV/dt)</code>.</p><p>To solve the semidefinite program, <code>JuMP.Model</code> requires an <code>optimizer_factory</code> capable of semidefinite programming (SDP). See the <a href="https://jump.dev/JuMP.jl/stable/installation/#Supported-solvers">JuMP documentation</a> for examples.</p><p>If <code>jac</code> is not supplied, the Jacobian of the <code>dynamics(x, p, t)</code> with respect to <code>x</code> is calculated using <code>ForwardDiff</code>. Otherwise, <code>jac</code> is expected to be either a function or an <code>AbstractMatrix</code>. If <code>jac isa Function</code>, it should take in the state and parameters and output the Jacobian of <code>dynamics</code> with respect to the state <code>x</code>. If <code>jac isa AbstractMatrix</code>, it should be the value of the Jacobian at <code>fixed_point</code>.</p><p>If <code>fixed_point</code> is not specified, it defaults to the origin, i.e., <code>zeros(state_dim)</code>. Parameters <code>p</code> for the dynamics should be supplied when the dynamics depend on them.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/local_lyapunov.jl#L1-L20">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.make_RoA_aware-Tuple{LyapunovDecreaseCondition}" href="#NeuralLyapunov.make_RoA_aware-Tuple{LyapunovDecreaseCondition}"><code>NeuralLyapunov.make_RoA_aware</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">make_RoA_aware(cond; ρ, out_of_RoA_penalty)</code></pre><p>Add awareness of the region of attraction (RoA) estimation task to the supplied <code>LyapunovDecreaseCondition</code></p><p><code>ρ</code> is the target level such that the RoA will be <code>{ x : V(x) ≤ ρ }</code>. <code>cond</code> specifies the loss applied when <code>V(state) ≤ ρ</code>, and <code>|out_of_RoA_penalty(V(state), dVdt(state), state, fixed_point, ρ)|^2</code> is the loss from <code>state</code> values such that <code>V(state) &gt; ρ</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/decrease_conditions_RoA_aware.jl#L66-L76">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.phi_to_net-Tuple{Any, Any}" href="#NeuralLyapunov.phi_to_net-Tuple{Any, Any}"><code>NeuralLyapunov.phi_to_net</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">phi_to_net(phi, θ[; idx])</code></pre><p>Return the network as a function of state alone.</p><p><strong>Arguments</strong></p><ul><li><code>phi</code>: the neural network, represented as <code>phi(x, θ)</code> if the neural network has a single       output, or a <code>Vector</code> of the same with one entry per neural network output.</li><li><code>θ</code>: the parameters of the neural network; <code>θ[:φ1]</code> should be the parameters of the first       neural network output (even if there is only one), <code>θ[:φ2]</code> the parameters of the       second (if there are multiple), and so on.</li><li><code>idx</code>: the neural network outputs to include in the returned function; defaults to all and       only applicable when <code>phi isa Vector</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/96f212569185ce0c68243fa2ff474beaf7afcae5/src/numerical_lyapunov_functions.jl#L91-L105">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Wednesday 8 May 2024 12:55">Wednesday 8 May 2024</span>. Using Julia version 1.10.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
