<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · NeuralLyapunov.jl</title><meta name="title" content="Home · NeuralLyapunov.jl"/><meta property="og:title" content="Home · NeuralLyapunov.jl"/><meta property="twitter:title" content="Home · NeuralLyapunov.jl"/><meta name="description" content="Documentation for NeuralLyapunov.jl."/><meta property="og:description" content="Documentation for NeuralLyapunov.jl."/><meta property="twitter:description" content="Documentation for NeuralLyapunov.jl."/><meta property="og:url" content="https://SciML.github.io/NeuralLyapunov.jl/"/><meta property="twitter:url" content="https://SciML.github.io/NeuralLyapunov.jl/"/><link rel="canonical" href="https://SciML.github.io/NeuralLyapunov.jl/"/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>NeuralLyapunov.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/NeuralLyapunov.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/NeuralLyapunov.jl/blob/master/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="NeuralLyapunov"><a class="docs-heading-anchor" href="#NeuralLyapunov">NeuralLyapunov</a><a id="NeuralLyapunov-1"></a><a class="docs-heading-anchor-permalink" href="#NeuralLyapunov" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/SciML/NeuralLyapunov.jl">NeuralLyapunov</a>.</p><ul><li><a href="#NeuralLyapunov.AbstractLyapunovDecreaseCondition"><code>NeuralLyapunov.AbstractLyapunovDecreaseCondition</code></a></li><li><a href="#NeuralLyapunov.AbstractLyapunovMinimizationCondition"><code>NeuralLyapunov.AbstractLyapunovMinimizationCondition</code></a></li><li><a href="#NeuralLyapunov.LyapunovDecreaseCondition"><code>NeuralLyapunov.LyapunovDecreaseCondition</code></a></li><li><a href="#NeuralLyapunov.LyapunovMinimizationCondition"><code>NeuralLyapunov.LyapunovMinimizationCondition</code></a></li><li><a href="#NeuralLyapunov.NeuralLyapunovSpecification"><code>NeuralLyapunov.NeuralLyapunovSpecification</code></a></li><li><a href="#NeuralLyapunov.NeuralLyapunovStructure"><code>NeuralLyapunov.NeuralLyapunovStructure</code></a></li><li><a href="#NeuralLyapunov.RoAAwareDecreaseCondition"><code>NeuralLyapunov.RoAAwareDecreaseCondition</code></a></li><li><a href="#NeuralLyapunov.AsymptoticDecrease-Tuple{}"><code>NeuralLyapunov.AsymptoticDecrease</code></a></li><li><a href="#NeuralLyapunov.DontCheckDecrease"><code>NeuralLyapunov.DontCheckDecrease</code></a></li><li><a href="#NeuralLyapunov.DontCheckNonnegativity-Tuple{}"><code>NeuralLyapunov.DontCheckNonnegativity</code></a></li><li><a href="#NeuralLyapunov.ExponentialDecrease-Tuple{Real}"><code>NeuralLyapunov.ExponentialDecrease</code></a></li><li><a href="#NeuralLyapunov.NeuralLyapunovPDESystem-Tuple{SciMLBase.ODEFunction, Any, Any, NeuralLyapunovSpecification}"><code>NeuralLyapunov.NeuralLyapunovPDESystem</code></a></li><li><a href="#NeuralLyapunov.NonnegativeNeuralLyapunov-Tuple{Integer}"><code>NeuralLyapunov.NonnegativeNeuralLyapunov</code></a></li><li><a href="#NeuralLyapunov.NumericalNeuralLyapunovFunctions-Tuple{Any, Any, Function, NeuralLyapunovStructure, Function, Any}"><code>NeuralLyapunov.NumericalNeuralLyapunovFunctions</code></a></li><li><a href="#NeuralLyapunov.NumericalNeuralLyapunovFunctions-Tuple{Any, Any, Function, Function, Function, Any}"><code>NeuralLyapunov.NumericalNeuralLyapunovFunctions</code></a></li><li><a href="#NeuralLyapunov.PositiveSemiDefinite-Tuple{}"><code>NeuralLyapunov.PositiveSemiDefinite</code></a></li><li><a href="#NeuralLyapunov.PositiveSemiDefiniteStructure-Tuple{Integer}"><code>NeuralLyapunov.PositiveSemiDefiniteStructure</code></a></li><li><a href="#NeuralLyapunov.StrictlyPositiveDefinite-Tuple{}"><code>NeuralLyapunov.StrictlyPositiveDefinite</code></a></li><li><a href="#NeuralLyapunov.UnstructuredNeuralLyapunov-Tuple{}"><code>NeuralLyapunov.UnstructuredNeuralLyapunov</code></a></li><li><a href="#NeuralLyapunov.check_decrease-Tuple{NeuralLyapunov.AbstractLyapunovDecreaseCondition}"><code>NeuralLyapunov.check_decrease</code></a></li><li><a href="#NeuralLyapunov.check_fixed_point-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}"><code>NeuralLyapunov.check_fixed_point</code></a></li><li><a href="#NeuralLyapunov.check_nonnegativity-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}"><code>NeuralLyapunov.check_nonnegativity</code></a></li><li><a href="#NeuralLyapunov.check_stationary_fixed_point-Tuple{NeuralLyapunov.AbstractLyapunovDecreaseCondition}"><code>NeuralLyapunov.check_stationary_fixed_point</code></a></li><li><a href="#NeuralLyapunov.get_decrease_condition-Tuple{NeuralLyapunov.AbstractLyapunovDecreaseCondition}"><code>NeuralLyapunov.get_decrease_condition</code></a></li><li><a href="#NeuralLyapunov.get_minimization_condition-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}"><code>NeuralLyapunov.get_minimization_condition</code></a></li><li><a href="#NeuralLyapunov.local_Lyapunov-Tuple{Function, Any, Any}"><code>NeuralLyapunov.local_Lyapunov</code></a></li><li><a href="#NeuralLyapunov.make_RoA_aware-Tuple{LyapunovDecreaseCondition}"><code>NeuralLyapunov.make_RoA_aware</code></a></li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.AbstractLyapunovDecreaseCondition" href="#NeuralLyapunov.AbstractLyapunovDecreaseCondition"><code>NeuralLyapunov.AbstractLyapunovDecreaseCondition</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractLyapunovDecreaseCondition</code></pre><p>Represents the decrease condition in a neural Lyapunov problem</p><p>All concrete <code>AbstractLyapunovDecreaseCondition</code> subtypes should define the <code>check_decrease</code>, <code>check_stationary_fixed_point</code>, and <code>get_decrease_condition</code> functions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/conditions_specification.jl#L33-L40">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.AbstractLyapunovMinimizationCondition" href="#NeuralLyapunov.AbstractLyapunovMinimizationCondition"><code>NeuralLyapunov.AbstractLyapunovMinimizationCondition</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractLyapunovMinimizationCondition</code></pre><p>Represents the minimization condition in a neural Lyapunov problem</p><p>All concrete <code>AbstractLyapunovMinimizationCondition</code> subtypes should define the <code>check_nonnegativity</code>, <code>check_fixed_point</code>, and <code>get_minimization_condition</code> functions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/conditions_specification.jl#L23-L30">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.LyapunovDecreaseCondition" href="#NeuralLyapunov.LyapunovDecreaseCondition"><code>NeuralLyapunov.LyapunovDecreaseCondition</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LyapunovDecreaseCondition(check_decrease, decrease, strength, relu, check_fixed_point)</code></pre><p>Specifies the form of the Lyapunov conditions to be used; if <code>check_decrease</code>, training will enforce <code>decrease(V, dVdt) ≤ strength(state, fixed_point)</code>.</p><p>The inequality will be approximated by the equation     <code>relu(decrease(V, dVdt) - strength(state, fixed_point)) = 0.0</code>. If <code>check_fixed_point</code> is <code>false</code>, then training assumes <code>dVdt(fixed_point) = 0</code>, but if <code>check_fixed_point</code> is <code>true</code>, then training will enforce <code>dVdt(fixed_point) = 0</code>.</p><p>If the dynamics truly have a fixed point at <code>fixed_point</code> and <code>dVdt</code> has been defined properly in terms of the dynamics, then <code>dVdt(fixed_point)</code> will be <code>0</code> and there is no need to enforce <code>dVdt(fixed_point) = 0</code>, so <code>check_fixed_point</code> defaults to <code>false</code>.</p><p><strong>Examples:</strong></p><p>Asymptotic decrease can be enforced by requiring     <code>dVdt ≤ -C |state - fixed_point|^2</code>, which corresponds to     <code>decrease = (V, dVdt) -&gt; dVdt</code>     <code>strength = (x, x0) -&gt; -C * (x - x0) ⋅ (x - x0)</code></p><p>Exponential decrease of rate <code>k</code> is proven by <code>dVdt ≤ - k * V</code>, so corresponds to     <code>decrease = (V, dVdt) -&gt; dVdt + k * V</code>     <code>strength = (x, x0) -&gt; 0.0</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/decrease_conditions.jl#L1-L27">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.LyapunovMinimizationCondition" href="#NeuralLyapunov.LyapunovMinimizationCondition"><code>NeuralLyapunov.LyapunovMinimizationCondition</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LyapunovMinimizationCondition</code></pre><p>Specifies the form of the Lyapunov conditions to be used.</p><p>If <code>check_nonnegativity</code> is <code>true</code>, training will attempt to enforce     <code>V(state) ≥ strength(state, fixed_point)</code>. The inequality will be approximated by the equation     <code>relu(strength(state, fixed_point) - V(state)) = 0.0</code>. If <code>check_fixed_point</code> is <code>true</code>, then training will also attempt to enforce     <code>V(fixed_point) = 0</code>.</p><p><strong>Examples</strong></p><p>The condition that the Lyapunov function must be minimized uniquely at the fixed point can be represented as <code>V(fixed_point) = 0</code>, <code>V(state) &gt; 0</code> when <code>state ≠ fixed_point</code>. This could be enfored by <code>V(fixed_point) ≥ ||state - fixed_point||^2</code>, which would be represented, with <code>check_nonnegativity = true</code>, by     strength(state, fixed<em>point) = ||state - fixed</em>point||^2, paired with <code>V(fixed_point) = 0</code>, which can be enforced with <code>check_fixed_point = true</code>.</p><p>If <code>V</code> were structured such that it is always nonnegative, then <code>V(fixed_point) = 0</code> is all that must be enforced in training for the Lyapunov function to be uniquely minimized at <code>fixed_point</code>. So, in that case, we would use     <code>check_nonnegativity = false;  check_fixed_point = true</code>.</p><p>In either case, <code>relu = (t) -&gt; max(0.0, t)</code> exactly represents the inequality, but approximations of this function are allowed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/minimization_conditions.jl#L1-L29">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.NeuralLyapunovSpecification" href="#NeuralLyapunov.NeuralLyapunovSpecification"><code>NeuralLyapunov.NeuralLyapunovSpecification</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NeuralLyapunovSpecification</code></pre><p>Specifies a neural Lyapunov problem</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/conditions_specification.jl#L43-L47">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.NeuralLyapunovStructure" href="#NeuralLyapunov.NeuralLyapunovStructure"><code>NeuralLyapunov.NeuralLyapunovStructure</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NeuralLyapunovStructure</code></pre><p>Specifies the structure of the neural Lyapunov function and its derivative.</p><p>Allows the user to define the Lyapunov in terms of the neural network to structurally enforce Lyapunov conditions. <code>network_dim</code> is the dimension of the output of the neural network. <code>V(phi::Function, state, fixed_point)</code> takes in the neural network, the state, and the fixed point, and outputs the value of the Lyapunov function at <code>state</code>. <code>V̇(phi::Function, J_phi::Function, f::Function, state, fixed_point)</code> takes in the neural network, the jacobian of the neural network, the dynamics (as a function of the state alone), the state, and the fixed point, and outputs the time derivative of the Lyapunov function at <code>state</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/conditions_specification.jl#L1-L15">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.RoAAwareDecreaseCondition" href="#NeuralLyapunov.RoAAwareDecreaseCondition"><code>NeuralLyapunov.RoAAwareDecreaseCondition</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RoAAwareDecreaseCondition(check_decrease, decrease, strength, relu, check_fixed_point,
                          ρ, out_of_RoA_penalty)</code></pre><p>Specifies the form of the Lyapunov conditions to be used, training for a region of attraction estimate of <code>{ x : V(x) ≤ ρ }</code></p><p>If <code>check_decrease</code>, training will enforce <code>decrease(V(state), dVdt(state)) ≤ strength(state, fixed_point)</code> whenever <code>V(state) ≤ ρ</code>, and will instead apply <code>|out_of_RoA_penalty(V(state), dVdt(state), state, fixed_point, ρ)|^2</code> when <code>V(state) &gt; ρ</code>.</p><p>The inequality will be approximated by the equation     <code>relu(decrease(V, dVdt) - strength(state, fixed_point)) = 0.0</code>. If <code>check_fixed_point</code> is <code>false</code>, then training assumes <code>dVdt(fixed_point) = 0</code>, but if <code>check_fixed_point</code> is <code>true</code>, then training will attempt to enforce <code>dVdt(fixed_point) = 0</code>.</p><p>If the dynamics truly have a fixed point at <code>fixed_point</code> and <code>dVdt</code> has been defined properly in terms of the dynamics, then <code>dVdt(fixed_point)</code> will be <code>0</code> and there is no need to enforce <code>dVdt(fixed_point) = 0</code>, so <code>check_fixed_point</code> defaults to <code>false</code>.</p><p><strong>Examples:</strong></p><p>Asymptotic decrease can be enforced by requiring     <code>dVdt ≤ -C |state - fixed_point|^2</code>, which corresponds to     <code>decrease = (V, dVdt) -&gt; dVdt</code> and     <code>strength = (x, x0) -&gt; -C * (x - x0) ⋅ (x - x0)</code>.</p><p>Exponential decrease of rate <code>k</code> is proven by <code>dVdt ≤ - k * V</code>, so corresponds to     <code>decrease = (V, dVdt) -&gt; dVdt + k * V</code> and     <code>strength = (x, x0) -&gt; 0.0</code>.</p><p>Enforcing either condition only in the region of attraction and not penalizing any points outside that region would correspond to     <code>out_of_RoA_penalty = (V, dVdt, state, fixed_point, ρ) -&gt; 0.0</code>, whereas an example of a penalty that decays farther in state space from the fixed point is     <code>out_of_RoA_penalty = (V, dVdt, state, fixed_point, ρ) -&gt; 1.0 / ((x - x0) ⋅ (x - x0))</code>. Note that this penalty could also depend on values of <code>V</code>, <code>dVdt</code>, and <code>ρ</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/decrease_conditions_RoA_aware.jl#L1-L41">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.AsymptoticDecrease-Tuple{}" href="#NeuralLyapunov.AsymptoticDecrease-Tuple{}"><code>NeuralLyapunov.AsymptoticDecrease</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">AsymptoticDecrease(strict; check_fixed_point, C)</code></pre><p>Constructs a <code>LyapunovDecreaseCondition</code> corresponding to asymptotic decrease.</p><p>If <code>strict</code> is <code>false</code>, the condition is <code>dV/dt ≤ 0</code>, and if <code>strict</code> is <code>true</code>, the condition is <code>dV/dt ≤ - C | state - fixed_point |^2</code>.</p><p>The inequality is represented by <code>a ≥ b</code> &lt;==&gt; <code>relu(b-a) = 0.0</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/decrease_conditions.jl#L54-L63">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.DontCheckDecrease" href="#NeuralLyapunov.DontCheckDecrease"><code>NeuralLyapunov.DontCheckDecrease</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">DontCheckDecrease(check_fixed_point = false)</code></pre><p>Constructs a <code>LyapunovDecreaseCondition</code> which represents not checking for decrease of the Lyapunov function along system trajectories. This is appropriate in cases when the Lyapunov decrease condition has been structurally enforced.</p><p>It is still possible to check for <code>dV/dt = 0</code> at <code>fixed_point</code>, even in this case.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/decrease_conditions.jl#L117-L125">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.DontCheckNonnegativity-Tuple{}" href="#NeuralLyapunov.DontCheckNonnegativity-Tuple{}"><code>NeuralLyapunov.DontCheckNonnegativity</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">DontCheckNonnegativity(check_fixed_point)</code></pre><p>Constructs a <code>LyapunovMinimizationCondition</code> which represents not checking for nonnegativity of the Lyapunov function. This is appropriate in cases where this condition has been structurally enforced.</p><p>It is still possible to check for <code>V(fixed_point) = 0</code>, even in this case, for example if <code>V</code> is structured to be positive for <code>state ≠ fixed_point</code>, but it is not guaranteed structurally that <code>V(fixed_point) = 0</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/minimization_conditions.jl#L98-L108">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.ExponentialDecrease-Tuple{Real}" href="#NeuralLyapunov.ExponentialDecrease-Tuple{Real}"><code>NeuralLyapunov.ExponentialDecrease</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ExponentialDecrease(k, strict; check_fixed_point, C)</code></pre><p>Constructs a <code>LyapunovDecreaseCondition</code> corresponding to exponential decrease of rate <code>k</code>.</p><p>If <code>strict</code> is <code>false</code>, the condition is <code>dV/dt ≤ -k * V</code>, and if <code>strict</code> is <code>true</code>, the condition is <code>dV/dt ≤ -k * V - C * ||state - fixed_point||^2</code>.</p><p>The inequality is represented by <code>a ≥ b</code> &lt;==&gt; <code>relu(b-a) = 0.0</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/decrease_conditions.jl#L85-L94">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.NeuralLyapunovPDESystem-Tuple{SciMLBase.ODEFunction, Any, Any, NeuralLyapunovSpecification}" href="#NeuralLyapunov.NeuralLyapunovPDESystem-Tuple{SciMLBase.ODEFunction, Any, Any, NeuralLyapunovSpecification}"><code>NeuralLyapunov.NeuralLyapunovPDESystem</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">NeuralLyapunovPDESystem(dynamics, lb, ub, spec; fixed_point, ps)</code></pre><p>Constructs a ModelingToolkit <code>PDESystem</code> to train a neural Lyapunov function</p><p>Returns the <code>PDESystem</code> and a function representing the neural network, which operates columnwise.</p><p>The neural Lyapunov function will only be trained for <code>{ x : lb .≤ x .≤ ub }</code>. The Lyapunov function will be for the dynamical system represented by <code>dynamics</code>. If <code>dynamics</code> is an <code>ODEProblem</code> or <code>ODEFunction</code>, then the corresponding ODE; if <code>dynamics</code> is a function, then the ODE is <code>ẋ = dynamics(x, p, t)</code>. This ODE should not depend on <code>t</code> (time <code>t=0.0</code> alone will be used) and should have a fixed point at <code>x = fixed_point</code>. The particular Lyapunov conditions to be used and structure of the neural Lyapunov function are specified through <code>spec</code>, which is a <code>NeuralLyapunovSpecification</code>.</p><p>The returned neural network function takes three inputs: the neural network structure <code>phi</code>, the trained network parameters, and a matrix of inputs to operate on columnwise.</p><p>If <code>dynamics</code> requires parameters, their values can be supplied through the Vector <code>p</code>, or through the parameters of <code>dynamics</code> if <code>dynamics isa ODEProblem</code> (in which case, let the other be <code>SciMLBase.NullParameters()</code>). If <code>dynamics</code> is an <code>ODEFunction</code> and <code>dynamics.paramsyms</code> is defined, then <code>p</code> should have the same order.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/NeuralLyapunovPDESystem.jl#L1-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.NonnegativeNeuralLyapunov-Tuple{Integer}" href="#NeuralLyapunov.NonnegativeNeuralLyapunov-Tuple{Integer}"><code>NeuralLyapunov.NonnegativeNeuralLyapunov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">NonnegativeNeuralLyapunov(network_dim, δ, pos_def; grad_pos_def, grad)</code></pre><p>Creates a <code>NeuralLyapunovStructure</code> where the Lyapunov function is the L2 norm of the neural network output plus a constant δ times a function <code>pos_def</code>.</p><p>The condition that the Lyapunov function must be minimized uniquely at the fixed point can be represented as <code>V(fixed_point) = 0</code>, <code>V(state) &gt; 0</code> when <code>state ≠ fixed_point</code>. This structure ensures <code>V(state) ≥ 0</code>. Further, if <code>δ &gt; 0</code> and <code>pos_def(fixed_point, fixed_point) = 0</code>, but <code>pos_def(state, fixed_point) &gt; 0</code> when <code>state ≠ fixed_point</code>, this ensures that <code>V(state) &gt; 0</code> when <code>state != fixed_point</code>. This does not enforce <code>V(fixed_point) = 0</code>, so that condition must included in the neural Lyapunov loss function.</p><p><code>grad_pos_def(state, fixed_point)</code> should be the gradient of <code>pos_def</code> with respect to <code>state</code> at <code>state</code>. If <code>grad_pos_def</code> is not defined, it is evaluated using <code>grad</code>, which defaults to <code>ForwardDiff.gradient</code>.</p><p>The neural network output has dimension <code>network_dim</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/structure_specification.jl#L16-L35">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.NumericalNeuralLyapunovFunctions-Tuple{Any, Any, Function, Function, Function, Any}" href="#NeuralLyapunov.NumericalNeuralLyapunovFunctions-Tuple{Any, Any, Function, Function, Function, Any}"><code>NeuralLyapunov.NumericalNeuralLyapunovFunctions</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">NumericalNeuralLyapunovFunctions(phi, θ, network_func, V_structure, dynamics,
                                 fixed_point, grad)</code></pre><p>Returns the Lyapunov function, its time derivative, and its gradient: <code>V(state)</code>, <code>V̇(state)</code>, and <code>∇V(state)</code>.</p><p>These functions can operate on a state vector or columnwise on a matrix of state vectors. <code>phi</code> is the neural network with parameters <code>θ</code>. <code>network_func</code> is an output of <code>NeuralLyapunovPDESystem</code>.</p><p>The Lyapunov function structure is defined by     <code>V_structure(_network_func, state, fixed_point)</code> Its gradient is calculated using <code>grad</code>, which defaults to <code>ForwardDiff.gradient</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/NeuralLyapunovPDESystem.jl#L331-L345">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.NumericalNeuralLyapunovFunctions-Tuple{Any, Any, Function, NeuralLyapunovStructure, Function, Any}" href="#NeuralLyapunov.NumericalNeuralLyapunovFunctions-Tuple{Any, Any, Function, NeuralLyapunovStructure, Function, Any}"><code>NeuralLyapunov.NumericalNeuralLyapunovFunctions</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">NumericalNeuralLyapunovFunctions(phi, θ, network_func, structure, dynamics, fixed_point;
                                 jac, J_net)</code></pre><p>Returns the Lyapunov function, its time derivative, and its gradient: <code>V(state)</code>, <code>V̇(state)</code>, and <code>∇V(state)</code></p><p>These functions can operate on a state vector or columnwise on a matrix of state vectors. <code>phi</code> is the neural network with parameters <code>θ</code>. <code>network_func(phi, θ, state)</code> is an output of <code>NeuralLyapunovPDESystem</code>, which evaluates the neural network represented by <code>phi</code> with parameters <code>θ</code> at <code>state</code>.</p><p>The Lyapunov function structure is specified in structure, which is a <code>NeuralLyapunovStructure</code>. The Jacobian of the network is either specified via <code>J_net(_phi, _θ, state)</code> or calculated using <code>jac</code>, which defaults to <code>ForwardDiff.jacobian</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/NeuralLyapunovPDESystem.jl#L271-L287">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.PositiveSemiDefinite-Tuple{}" href="#NeuralLyapunov.PositiveSemiDefinite-Tuple{}"><code>NeuralLyapunov.PositiveSemiDefinite</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">PositiveSemiDefinite(check_fixed_point)</code></pre><p>Constructs a <code>LyapunovMinimizationCondition</code> representing     <code>V(state) ≥ 0</code>. If <code>check_fixed_point</code> is <code>true</code>, then training will also attempt to enforce     <code>V(fixed_point) = 0</code>.</p><p>The inequality is represented by <code>a ≥ b</code> &lt;==&gt; <code>relu(b-a) = 0.0</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/minimization_conditions.jl#L76-L85">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.PositiveSemiDefiniteStructure-Tuple{Integer}" href="#NeuralLyapunov.PositiveSemiDefiniteStructure-Tuple{Integer}"><code>NeuralLyapunov.PositiveSemiDefiniteStructure</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">PositiveSemiDefiniteStructure(network_dim; pos_def, non_neg, grad_pos_def, grad_non_neg, grad)</code></pre><p>Creates a <code>NeuralLyapunovStructure</code> where the Lyapunov function is the product of a positive (semi-)definite function <code>pos_def</code> which does not depend on the network and a nonnegative function non_neg which does depend the network.</p><p>The condition that the Lyapunov function must be minimized uniquely at the fixed point can be represented as <code>V(fixed_point) = 0</code>, <code>V(state) &gt; 0</code> when <code>state ≠ fixed_point</code>. This structure ensures <code>V(state) ≥ 0</code>. Further, if <code>pos_def</code> is <code>0</code> only at <code>fixed_point</code> (and positive elsewhere) and if <code>non_neg</code> is strictly positive away from <code>fixed_point</code> (as is the case for the default values of <code>pos_def</code> and <code>non_neg</code>), then this structure ensures <code>V(fixed_point) = 0</code> and <code>V(state) &gt; 0</code> when <code>state ≠ fixed_point</code>.</p><p><code>grad_pos_def(state, fixed_point)</code> should be the gradient of <code>pos_def</code> with respect to <code>state</code> at <code>state</code>. Similarly, <code>grad_non_neg(net, J_net, state, fixed_point)</code> should be the gradient of <code>non_neg(net, state, fixed_point)</code> with respect to <code>state</code> at <code>state</code>. If <code>grad_pos_def</code> or <code>grad_non_neg</code> is not defined, it is evaluated using <code>grad</code>, which defaults to <code>ForwardDiff.gradient</code>.</p><p>The neural network output has dimension <code>network_dim</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/structure_specification.jl#L74-L95">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.StrictlyPositiveDefinite-Tuple{}" href="#NeuralLyapunov.StrictlyPositiveDefinite-Tuple{}"><code>NeuralLyapunov.StrictlyPositiveDefinite</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">StrictlyPositiveDefinite(C; check_fixed_point, relu)</code></pre><p>Constructs a <code>LyapunovMinimizationCondition</code> representing     <code>V(state) ≥ C * ||state - fixed_point||^2</code>. If <code>check_fixed_point</code> is <code>true</code>, then training will also attempt to enforce     <code>V(fixed_point) = 0</code>.</p><p>The inequality is represented by <code>a ≥ b</code> &lt;==&gt; <code>relu(b-a) = 0.0</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/minimization_conditions.jl#L53-L62">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.UnstructuredNeuralLyapunov-Tuple{}" href="#NeuralLyapunov.UnstructuredNeuralLyapunov-Tuple{}"><code>NeuralLyapunov.UnstructuredNeuralLyapunov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">UnstructuredNeuralLyapunov()</code></pre><p>Creates a <code>NeuralLyapunovStructure</code> where the Lyapunov function is the neural network evaluated at the state. This does not structurally enforce any Lyapunov conditions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/structure_specification.jl#L1-L6">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.check_decrease-Tuple{NeuralLyapunov.AbstractLyapunovDecreaseCondition}" href="#NeuralLyapunov.check_decrease-Tuple{NeuralLyapunov.AbstractLyapunovDecreaseCondition}"><code>NeuralLyapunov.check_decrease</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">check_decrease(cond::AbstractLyapunovDecreaseCondition)</code></pre><p><code>true</code> if <code>cond</code> specifies training to meet the Lyapunov decrease condition, <code>false</code> if <code>cond</code> specifies no training to meet this condition.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/conditions_specification.jl#L87-L92">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.check_fixed_point-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}" href="#NeuralLyapunov.check_fixed_point-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}"><code>NeuralLyapunov.check_fixed_point</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">check_fixed_point(cond::AbstractLyapunovMinimizationCondition)</code></pre><p><code>true</code> if <code>cond</code> specifies training for the Lyapunov function to equal zero at the fixed point, <code>false</code> if <code>cond</code> specifies no training to meet this condition.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/conditions_specification.jl#L65-L70">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.check_nonnegativity-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}" href="#NeuralLyapunov.check_nonnegativity-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}"><code>NeuralLyapunov.check_nonnegativity</code></a> — <span class="docstring-category">Method</span></header><section><div><p>check_nonnegativity(cond::AbstractLyapunovMinimizationCondition)</p><p><code>true</code> if <code>cond</code> specifies training to meet the Lyapunov minimization condition, <code>false</code> if <code>cond</code> specifies no training to meet this condition.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/conditions_specification.jl#L54-L59">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.check_stationary_fixed_point-Tuple{NeuralLyapunov.AbstractLyapunovDecreaseCondition}" href="#NeuralLyapunov.check_stationary_fixed_point-Tuple{NeuralLyapunov.AbstractLyapunovDecreaseCondition}"><code>NeuralLyapunov.check_stationary_fixed_point</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">check_stationary_fixed_point(cond::AbstractLyapunovDecreaseCondition)</code></pre><p><code>true</code> if <code>cond</code> specifies training for the Lyapunov function not to change at the fixed point, <code>false</code> if <code>cond</code> specifies no training to meet this condition.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/conditions_specification.jl#L98-L103">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.get_decrease_condition-Tuple{NeuralLyapunov.AbstractLyapunovDecreaseCondition}" href="#NeuralLyapunov.get_decrease_condition-Tuple{NeuralLyapunov.AbstractLyapunovDecreaseCondition}"><code>NeuralLyapunov.get_decrease_condition</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_decrease_condition(cond::AbstractLyapunovDecreaseCondition)</code></pre><p>Returns a function of <code>V</code>, <code>dVdt</code>, <code>state</code>, and <code>fixed_point</code> that is equal to zero when the Lyapunov decrease condition is met and greater than zero when it is violated.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/conditions_specification.jl#L109-L114">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.get_minimization_condition-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}" href="#NeuralLyapunov.get_minimization_condition-Tuple{NeuralLyapunov.AbstractLyapunovMinimizationCondition}"><code>NeuralLyapunov.get_minimization_condition</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_minimization_condition(cond::AbstractLyapunovMinimizationCondition)</code></pre><p>Returns a function of <code>V</code>, <code>state</code>, and <code>fixed_point</code> that equals zero when the Lyapunov minimization condition is met and greater than zero when it&#39;s violated.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/conditions_specification.jl#L76-L81">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.local_Lyapunov-Tuple{Function, Any, Any}" href="#NeuralLyapunov.local_Lyapunov-Tuple{Function, Any, Any}"><code>NeuralLyapunov.local_Lyapunov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_local_Lyapunov(dynamics, state_dim; fixed_point, dynamics_jac)</code></pre><p>Uses semidefinite programming to derive a quadratic Lyapunov function for the linearization of dynamics around fixed_point. Returns (V, dV/dt, ∇V).</p><p>If dynamics<em>jac is nothing, the Jacobian of the dynamics is calculated using  ForwardDiff. Other allowable forms are a function which takes in the state and outputs the jacobian of dynamics or an AbstractMatrix representing the Jacobian at fixed</em>point. If fixed_point is not specified, it defaults to the origin.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/local_Lyapunov.jl#L1-L12">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralLyapunov.make_RoA_aware-Tuple{LyapunovDecreaseCondition}" href="#NeuralLyapunov.make_RoA_aware-Tuple{LyapunovDecreaseCondition}"><code>NeuralLyapunov.make_RoA_aware</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">make_RoA_aware(cond; ρ, out_of_RoA_penalty)</code></pre><p>Adds awareness of the region of attraction (RoA) estimation task to the supplied <code>LyapunovDecreaseCondition</code></p><p><code>ρ</code> is the target level such that the RoA will be <code>{ x : V(x) ≤ ρ }</code>. <code>cond</code> specifies the loss applied when <code>V(state) ≤ ρ</code>, and <code>|out_of_RoA_penalty(V(state), dVdt(state), state, fixed_point, ρ)|^2</code> is the loss from <code>state</code> values such that <code>V(state) &gt; ρ</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/213010015628938789f6c3f80ebc7de1edab34ce/src/decrease_conditions_RoA_aware.jl#L74-L84">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Thursday 7 March 2024 19:14">Thursday 7 March 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
