<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Benchmarking neural Lyapunov methods · NeuralLyapunov.jl</title><meta name="title" content="Benchmarking neural Lyapunov methods · NeuralLyapunov.jl"/><meta property="og:title" content="Benchmarking neural Lyapunov methods · NeuralLyapunov.jl"/><meta property="twitter:title" content="Benchmarking neural Lyapunov methods · NeuralLyapunov.jl"/><meta name="description" content="Documentation for NeuralLyapunov.jl."/><meta property="og:description" content="Documentation for NeuralLyapunov.jl."/><meta property="twitter:description" content="Documentation for NeuralLyapunov.jl."/><meta property="og:url" content="https://docs.sciml.ai/NeuralLyapunov/stable/man/benchmarking/"/><meta property="twitter:url" content="https://docs.sciml.ai/NeuralLyapunov/stable/man/benchmarking/"/><link rel="canonical" href="https://docs.sciml.ai/NeuralLyapunov/stable/man/benchmarking/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NeuralLyapunov.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralLyapunov.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../">Components of a Neural Lyapunov Problem</a></li><li><a class="tocitem" href="../pdesystem/">Solving a Neural Lyapunov Problem</a></li><li><a class="tocitem" href="../minimization/">Lyapunov Minimization Condition</a></li><li><a class="tocitem" href="../decrease/">Lyapunov Decrease Condition</a></li><li><a class="tocitem" href="../structure/">Structuring a Neural Lyapunov function</a></li><li><a class="tocitem" href="../roa/">Training for Region of Attraction Identification</a></li><li><a class="tocitem" href="../policy_search/">Policy Search and Network-Dependent Dynamics</a></li><li><a class="tocitem" href="../local_lyapunov/">Local Lyapunov analysis</a></li></ul></li><li><span class="tocitem">Demonstrations</span><ul><li><a class="tocitem" href="../../demos/damped_SHO/">Damped Simple Harmonic Oscillator</a></li><li><a class="tocitem" href="../../demos/roa_estimation/">Estimating the Region of Attraction</a></li><li><a class="tocitem" href="../../demos/policy_search/">Policy Search on the Driven Inverted Pendulum</a></li><li><a class="tocitem" href="../../demos/benchmarking/">Benchmarking a neural Lyapunov method</a></li></ul></li><li><span class="tocitem">Test Problem Library</span><ul><li><a class="tocitem" href="../../lib/">NeuralLyapunovProblemLibrary.jl</a></li><li><a class="tocitem" href="../../lib/pendulum/">Pendulum Model</a></li><li><a class="tocitem" href="../../lib/double_pendulum/">Double Pendulum Model</a></li><li><a class="tocitem" href="../../lib/quadrotor/">Quadrotor Models</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Benchmarking neural Lyapunov methods</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Benchmarking neural Lyapunov methods</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/NeuralLyapunov.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/NeuralLyapunov.jl/blob/master/docs/src/man/benchmarking.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Benchmarking-neural-Lyapunov-methods"><a class="docs-heading-anchor" href="#Benchmarking-neural-Lyapunov-methods">Benchmarking neural Lyapunov methods</a><a id="Benchmarking-neural-Lyapunov-methods-1"></a><a class="docs-heading-anchor-permalink" href="#Benchmarking-neural-Lyapunov-methods" title="Permalink"></a></h1><p>To facilitate comparison of different neural Lyapunov specifications, optimizers, hyperparameters, etc., we provide the <a href="#NeuralLyapunov.benchmark"><code>benchmark</code></a> function.</p><p>Through its arguments, users may specify how a neural Lyapunov problem, the neural network structure, the physics-informed neural network discretization strategy, and the optimization strategy used to solve the problem. After solving the problem in the specified manner, the dynamical system is simulated (users can specify an ODE solver in the arguments, as well) and classification by the neural Lyapunov function is compared to the simulation results. The <a href="#NeuralLyapunov.benchmark"><code>benchmark</code></a> function returns a confusion matrix for the resultant neural Lyapunov classifier, the training time, and samples with labels, so that users can compare accuracy and computation speed of various methods.</p><article><details class="docstring" open="true"><summary id="NeuralLyapunov.benchmark"><a class="docstring-binding" href="#NeuralLyapunov.benchmark"><code>NeuralLyapunov.benchmark</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">benchmark(dynamics, bounds, spec, chain, strategy, opt; &lt;keyword_arguments&gt;)
benchmark(dynamics, lb, ub, spec, chain, strategy, opt; &lt;keyword_arguments&gt;)</code></pre><p>Evaluate the specified neural Lyapunov method on the given system. Return a <code>NamedTuple</code> containing the confusion matrix, optimization time, and other metrics listed below.</p><p>Train a neural Lyapunov function as specified, then discretize the domain using a grid discretization and use the neural Lyapnov function to and the provided <code>classifier</code> to predict whether grid points are in the region of attraction of the provided <code>fixed_point</code>. Finally, simulate the system from each grid point and check if the trajectories reach the fixed point. Return a confusion matrix for the neural Lyapunov classifier using the results of the simulated trajectories as ground truth. Additionally return the time it took for the optimization to run.</p><p>To train with multiple solvers, users should supply a vector of optimizers in <code>opt</code>. The first optimizer will be used, then the problem will be remade with the result of the first optimization as the initial guess. Then, the second optimizer will be used, and so on. Supplying a vector of <code>Pair</code>s in <code>optimization_args</code> will use the same arguments for each optimization pass, and supplying a vector of such vectors will use potentially different arguments for each optimization pass.</p><p>To train using GPU, users must provide an <code>init_params</code> stored on the GPU. Even in that case, the returned parameters <code>θ</code> will be moved to the CPU, which does not interfere at all with use of <a href="https://docs.sciml.ai/DiffEqGPU/stable/manual/ensemblegpuarray/"><code>EnsembleGPUArray</code></a> for the evaluation simulations.</p><p>When <code>init_params</code> or <code>init_states</code> are not provided, they are generated using <code>Lux.initialparameters</code> or <code>Lux.initialstates</code>, respectively. In that case, the type of any floating point parameters is inferred from <code>simulation_time</code>, the system parameters, and the bounds, in that order. If any of those are not floats (e.g., integers), the next is considered. If none are floats, <code>Float64</code> is used. This inference is important, since simulation fails when the output type of the dynamics differs from the type of the state divided by the type of <code>simulation_time</code>. For this reason, the <code>simulation_time</code> passed into the ODE solver is converted to the same type as the network parameters (whether supplied by the user or generated automatically).</p><p><strong>Positional Arguments</strong></p><ul><li><code>dynamics</code>: the dynamical system being analyzed, represented as a <code>System</code> or the function <code>f</code> such that <code>ẋ = f(x[, u], p, t)</code>; either way, the ODE should not depend on time and only <code>t = 0.0</code> will be used. (For an example of when <code>f</code> would have a <code>u</code> argument, see <a href="../policy_search/#NeuralLyapunov.add_policy_search"><code>add_policy_search</code></a>.)</li><li><code>bounds</code>: an array of domains, defining the training domain by bounding the states (and derivatives, when applicable) of <code>dynamics</code>; only used when <code>dynamics isa System</code>, otherwise use <code>lb</code> and <code>ub</code>.</li><li><code>lb</code> and <code>ub</code>: the training domain will be <span>$[lb_1, ub_1]×[lb_2, ub_2]×...$</span>; not used when <code>dynamics isa System</code>, then use <code>bounds</code>.</li><li><code>spec</code>: a <a href="../#NeuralLyapunov.NeuralLyapunovSpecification"><code>NeuralLyapunovSpecification</code></a> defining the Lyapunov function structure, as well as the minimization and decrease conditions.</li><li><code>chain</code>: a vector of Lux/Flux chains with a d-dimensional input and a 1-dimensional output corresponding to each of the dependent variables, where d is the length of <code>bounds</code> or <code>lb</code> and <code>ub</code>. Note that this specification respects the order of the dependent variables as specified in the PDESystem. Flux chains will be converted to Lux internally by NeuralPDE using <code>NeuralPDE.adapt(FromFluxAdaptor(false, false), chain)</code>.</li><li><code>strategy</code>: determines which training strategy will be used. See the NeuralPDE Training Strategy documentation for more details.</li><li><code>opt</code>: optimizer to use in training the neural Lyapunov function.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>n</code>: number of samples used for evaluating the neural Lyapunov classifier.</li><li><code>sample_alg</code>: sampling algorithm used for generating the evaluation data; defaults to <code>LatinHypercubeSample(rng)</code>; see the <a href="https://docs.sciml.ai/QuasiMonteCarlo/stable/samplers/">QuasiMonteCarlo.jl docs</a> for more information.</li><li><code>classifier</code>: function of <span>$V(x)$</span>, <span>$V̇(x)$</span>, and <span>$x$</span> that predicts whether <span>$x$</span> is in the region of attraction; when constructing the confusion matrix, a point is predicted to be in the region of attraction if <code>classifier</code> or <code>endpoint_check</code> returns <code>true</code>; defaults to <code>(V, V̇, x) -&gt; V̇ &lt; 0</code>.</li><li><code>fixed_point</code>: the equilibrium being analyzed; defaults to the origin.</li><li><code>p</code>: the values of the parameters of the dynamical system being analyzed; defaults to <code>SciMLBase.NullParameters()</code>; not used when <code>dynamics isa System</code>, then use the default parameter values of <code>dynamics</code>.</li><li><code>state_syms</code>: an array of the <code>Symbol</code> representing each state; not used when <code>dynamics isa System</code> (in that case, the symbols from <code>dynamics</code> are used); if <code>dynamics</code> is an <code>ODEFunction</code> or an <code>ODEInputFunction</code>, the symbols stored there are used, unless overridden here; if not provided here and cannot be inferred, <code>[:state1, :state2, ...]</code> will be used.</li><li><code>parameter_syms</code>: an array of the <code>Symbol</code> representing each parameter; not used when <code>dynamics isa System</code> (in that case, the symbols from <code>dynamics</code> are used); if <code>dynamics</code> is an <code>ODEFunction</code> or an <code>ODEInputFunction</code>, the symbols stored there are used, unless overridden here; if not provided here and cannot be inferred, <code>[:param1, :param2, ...]</code> will be used.</li><li><code>policy_search::Bool</code>: whether or not to include a loss term enforcing <code>fixed_point</code> to actually be a fixed point; defaults to <code>false</code>; when <code>dynamics isa System</code>, the value is inferred by the presence of unbound inputs and when <code>dynamics</code> is an <code>ODEFunction</code> or an <code>ODEInputFunction</code>, the value is inferred by the type of <code>dynamics</code>.</li><li><code>optimization_args</code>: arguments to be passed into the optimization solver, as a vector of <code>Pair</code>s. For more information, see the <a href="https://docs.sciml.ai/Optimization/stable/API/solve/">Optimization.jl docs</a>.</li><li><code>log_frequency</code>: frequency (in iterations) at which to log the training loss; defaults to <code>50</code>.</li><li><code>simulation_time</code>: simulation end time for checking if trajectory from a point reaches equilibrium</li><li><code>ode_solver</code>: differential equation solver used in simulating the system for evaluation. For more information, see the <a href="https://docs.sciml.ai/DiffEqDocs/stable/solvers/ode_solve/">DifferentialEquations.jl docs</a>.</li><li><code>ode_solver_args</code>: arguments to be passed into the differential equation solver. For more information, see the <a href="https://docs.sciml.ai/DiffEqDocs/stable/basics/common_solver_opts/">DifferentialEquations.jl docs</a>.</li><li><code>ensemble_alg</code>: controls how the evaluation simulations are handled; defaults to <code>EnsembleDistributed()</code>, which uses <code>pmap</code> internally; see the <a href="https://docs.sciml.ai/DiffEqDocs/stable/features/ensemble/">DifferentialEquations.jl docs</a> for more information.</li><li><code>endpoint_check</code>: function of the endpoint of a simulation that returns <code>true</code> when the endpoint is approximately the fixed point and <code>false</code> otherwise; defaults to <code>(x) -&gt; ≈(x, fixed_point; atol=atol)</code>.</li><li><code>atol</code>: absolute tolerance used in the default value for <code>endpoint_check</code>.</li><li><code>init_params</code>: initial parameters for the neural network; defaults to <code>nothing</code>, in which case the initial parameters are generated using <code>Lux.initialparameters</code> and <code>rng</code>.</li><li><code>init_states</code>: initial states for the neural network; defaults to <code>nothing</code>, in which case the initial states are generated using <code>Lux.initialstates</code> and <code>rng</code>. <code>init_states</code> should be stored on the same device as <code>init_params</code>.</li><li><code>rng</code>: random number generator used to generate initial parameters and states, as well as in the default sampling algorithm; defaults to a <code>StableRNG</code> with seed <code>0</code>.</li></ul><p><strong>Output Fields</strong></p><ul><li><code>confusion_matrix</code>: confusion matrix of the neural Lyapunov classifier.</li><li><code>data</code>: a <code>DataFrame</code> containing the following columns:<ul><li>&quot;Initial State&quot;: initial state of the simulation.</li><li>&quot;Final State&quot;: end state of the simulation.</li><li>&quot;V&quot;: value of the Lyapunov function at the initial state.</li><li>&quot;dVdt&quot;: value of the Lyapunov decrease function at the initial state.</li><li>&quot;Predicted in RoA&quot;: whether <code>classifier</code> predicted that the initial state is in the region of attraction.</li><li>&quot;Actually in RoA&quot;: whether the endpoint of the simulation is approximately equal to <code>fixed_point</code> (as determined by <code>endpoint_check</code>).</li><li>&quot;Classification&quot;: classification of each point, either &quot;TP&quot; (true positive), &quot;TN&quot; (true negative), &quot;FP&quot; (false positive), or &quot;FN&quot; (false negative).</li></ul></li><li><code>training_time</code>: time taken to train the neural Lyapunov function (in seconds).</li><li><code>θ</code>: the parameters of the neural Lyapunov function.</li><li><code>phi</code>: the neural network, represented as <code>phi(x, θ)</code> if the neural network has a single output, or a <code>Vector</code> of the same with one entry per neural network output (to be used with <a href="../pdesystem/#NeuralLyapunov.get_numerical_lyapunov_function"><code>get_numerical_lyapunov_function</code></a>).</li><li><code>V</code>: the neural Lyapunov function.</li><li><code>V̇</code>: the Lyapunov decrease function.</li><li><code>training_losses</code>: a <code>DataFrame</code> containing the training losses logged during training, with columns:<ul><li>&quot;Iteration&quot;: iteration number at which the loss was logged.</li><li>&quot;Loss&quot;: the full weighted training loss at that iteration.</li></ul></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NeuralLyapunov.jl/blob/b3755cc5c460eeb36be40a73dadf17cd2a860eaf/src/benchmark_harness.jl#L1-L141">source</a></section></details></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Friday 30 January 2026 00:44">Friday 30 January 2026</span>. Using Julia version 1.11.8.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
